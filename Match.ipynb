{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching 20201105\n",
    "\n",
    "Compares a list of masses and labels generated with CompoundCalculator to an input peak list. It is convenient to open the Calculator and Match notebooks in side-by-side windows (Jupyter Lab allows this) so it is easy to update the target ion list and repeat the matching.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The program matches the target ion and peak lists using a tolerance that can be specified in amu (fixed( or ppm (increases with mass). If both are non-zero the ppm is calulated and the larger window used which allows the window to increase with mass but never be less that a certain value. The program also allows for the possibility that complex peak and target ion lists can result in multiple matches for each peak. The function that prints the matches has a simplify mode which shows only one match for each peak but appends a string showing the number of matches; the match shown is the one with the smallest absolute error. Matched peaks can be grouped according to the 'root' field, which is part of the target ion list, and there is a cell that shows peaks with redundant matches to emphasize their existence and allow adjustment of the matching or ion generation parameters if necessary.\n",
    "\n",
    "Unmatched peaks greater than a given intensity threshold (percent base peak intensity) are also displayed. The idea is that this is part of interactive spectrum interpretation, i.e. once the origin of unmatched peaks is understood the ion generation parameters can be adjusted and applied to other peaks.\n",
    "\n",
    "In order to ensure that isotope peaks stay with the monoisotopic peaks, the program only searches for 13C peaks for matched peaks. Identified isotope peaks are Peaks identified as isotopes can also match entries in the target ion list so other possibilities are shown. In the output lists each peak has an index as well as the index of a related monoisotopic peak; these are the same for actual monoisotopic peaks.\n",
    "\n",
    "The peak list must be tab-delimited and have mass values but can also contain columns for Retention Time (RT) and Intensity; the function that reads the peak list tries to determine which columns are present.\n",
    "\n",
    "Results can be saved in several ways including a simple mass/intensity list and more detailed lists. Text lists can be imported into PeakView as spectra and overlaid on the original data to visualize the matches and highlight unmatched peaks.\n",
    "\n",
    "## Imports and function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime \n",
    "from collections import namedtuple\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some named tuples to hold the data and results\n",
    "Peak = namedtuple('Peak', 'Mass Inten RT')\n",
    "Target = namedtuple('Target', 'Mass Root Label')\n",
    "\n",
    "# a match contains the index of the peak, the calculated ion it matches, the index of the monoisotopic peak (if applicable) and the mass error\n",
    "# the latter fields allow the matched lists to be redily sorted and filtered\n",
    "Match = namedtuple('Match', 'Pk_index TargetIon MonoPeak Error')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_from_line(line):\n",
    "    \"\"\"\n",
    "    Split a line into parts and try to convert them to numbers...return the list of numbers or fields\n",
    "    \"\"\"\n",
    "    \n",
    "    parts = line.split()\n",
    "    \n",
    "    try:\n",
    "        vals = [float(field) for field in parts]  # convert all to numbers\n",
    "        success = True\n",
    "    except:\n",
    "        vals = parts      # return the fields if the conversion fails\n",
    "        success = False\n",
    "    \n",
    "    return success, vals\n",
    "    \n",
    "    \n",
    "def read_peak_list(peak_file_path):\n",
    "    \"\"\"\n",
    "    Reads a tab-delimited text file generating a list of Peak tuples (Mass, Inten, RT). Mass must be present but the other fields are optional\n",
    "    and will be stored internally as zero if absent.\n",
    "    If the file has only one column it is assumed to contain masses otherwise the code assumes that the first column is Mass,\n",
    "    the second is Inten and the RT is absent.\n",
    "    If the file contains a header line it is used to define the order of the columns by looking for matches with common labels\n",
    "    e.g. mz, m/z, Mass, etc. for masses. The RT column can only be used via a header line containi 'RT' or 'rt'\n",
    "    \"\"\"\n",
    "    mass_col = 0\n",
    "    inten_col = 1\n",
    "    rt_col = -1\n",
    "    has_rt = False\n",
    "    has_inten = True\n",
    "    start_line= 0\n",
    "    \n",
    "    peaks = []    #list of (mass, inten, RT) tuples\n",
    "\n",
    "    # read all the lines so we can process them one-by-one\n",
    "    with open(peak_file_path, 'r') as f:  \n",
    "    \n",
    "        lines = f.readlines()\n",
    "        \n",
    "        f.close()\n",
    "    \n",
    "    success, vals = values_from_line(lines[0])  # try to convert the first line\n",
    "    \n",
    "    if not success:   # couldn't get values; probably a header....vals is a list of the parts\n",
    "\n",
    "        # see if we can figure out what the columns are...lsist can be extende if needed\n",
    "        for col_index, col in enumerate(vals):\n",
    "            if col in ['mz', 'm/z', 'mass', 'Mass', 'Mass/Charge']: mass_col = col_index\n",
    "            if col in ['Int', 'Inten', 'inten', 'Height']: inten_col = col_index\n",
    "            if col in ['RT', 'rt']: rt_col = col_index\n",
    "\n",
    "        has_rt = rt_col > -1\n",
    "        has_inten = inten_col > -1\n",
    "            \n",
    "        start_line = 1     # can skip this line\n",
    "\n",
    "        print('m:', mass_col, 'Int:', inten_col, 'RT:', rt_col)\n",
    "\n",
    "    # Process line by line. Lines that cannot be converted to numbers are reported \n",
    "    # Note: the first line will be reprocessed if it is numeric\n",
    "    for line in lines[start_line:]:        \n",
    "\n",
    "        # get a list of numbers from the fields in the line - success will be false if this fails and vals will be the actual text parts\n",
    "        success, vals = values_from_line(line)  \n",
    "               \n",
    "        if success:\n",
    "            mass = vals[mass_col]\n",
    "            rt = vals[rt_col] if has_rt else 0\n",
    "            inten = vals[inten_col] if has_inten else 0\n",
    "            \n",
    "            p = Peak(mass, inten, rt)\n",
    "              \n",
    "            peaks.append(p) \n",
    "            \n",
    "        else:\n",
    "            print('Problem in line:', line, vals)   # vals will be the list of fields if there's a problem\n",
    "    \n",
    "    peaks = sorted(peaks, key = lambda x: x.Mass)     # ensure the list is sorted by mass\n",
    "\n",
    "    masses, intens, rts = zip(*peaks)\n",
    "\n",
    "    # Note: intensity params will be 0 if there is no intensity column\n",
    "    return peaks, sum(intens), max(intens), has_rt    # peaks, tic, base_peak_inten, sum rts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ion_list(ion_file_path):\n",
    "    \"\"\"\n",
    "    Read the taget ion file which is assumed to contain fields for mass, root and label that can be convertes to a Target\n",
    "    \"\"\"\n",
    "    \n",
    "    ions = []            #list of (mass, root, label) tuples\n",
    "    cond_str = \"\"        # conditions line if ptrsdrnt\n",
    "    \n",
    "    with open(ion_file_path, 'r') as f:  \n",
    "    \n",
    "        for line in f:\n",
    "            \n",
    "            if line[0] == '#':             # if the first character is '#' this is a condition line\n",
    "                cond_str = line[1:]\n",
    "                continue\n",
    "            \n",
    "            parts = line.split()\n",
    "            \n",
    "            try:\n",
    "                ion = Target(float(parts[0]), parts[1], parts[2])\n",
    "                ions.append(ion) \n",
    "            except:\n",
    "                print('Problem in', line)\n",
    "\n",
    "        f.close()\n",
    "    \n",
    "    ions = sorted(ions, key = lambda x: x.Mass)     # ensure the list is sorted by mass\n",
    "\n",
    "    return ions, cond_str    # target ions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mz_window(mz, amu, ppm):\n",
    "    \"\"\"\n",
    "    Determine the mass window to use for matching either as ppm or amu.\n",
    "    If both are supplied the larger will be used; this allows the window to increase with mass (ppm) but\n",
    "    never be smaller than amu.\n",
    "    If either is zero, the other is automatically used    \n",
    "    \"\"\"\n",
    "    ppm_window = mz * ppm /1e6\n",
    "    \n",
    "    if ppm_window > amu:\n",
    "        return ppm_window\n",
    "    else:\n",
    "        return amu\n",
    "    \n",
    "def get_mass_limits(mz, amu, ppm):\n",
    "    \"\"\"\n",
    "    Uses get_mz_window to determine the window size and returns the upper an lower mass limits\n",
    "    \"\"\"\n",
    "    window = get_mz_window(mz, amu, ppm)\n",
    "    return mz - window, mz + window\n",
    "\n",
    "# demonstartes how the window varies with mass\n",
    "# for mz in [100,200,300,400,500,600,700,800,900,1000]:\n",
    "#     print(mz, get_mz_window(mz, 0.005, 15), get_mass_limits(mz, 0.005, 15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_stats(matches, peaks, tic):\n",
    "    \"\"\"\n",
    "    Given lists of peaks and matches, returns the indices of the matched peaks and the percentage\n",
    "    of the TIC that they explain\n",
    "    \"\"\"\n",
    "\n",
    "    matched_indices = set([m.Pk_index for m in matches])   # get the peak indices; we uae a set so each peak occurs only once\n",
    "\n",
    "    matched_inten = sum([peaks[i].Inten for i in matched_indices])  # sum the intensities\n",
    "\n",
    "    percent_matched = matched_inten * 100/tic\n",
    "    \n",
    "    return matched_indices, percent_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redundant_matches(matches):\n",
    "    \"\"\"\n",
    "    Find which peaks have multiple matches.\n",
    "    We group the matches by peak index and then find which groups have more than one entry\n",
    "    We return the count and the redundant groups individually sorted by absolute error\n",
    "    \"\"\"\n",
    "    redundant = []\n",
    "    redundant_peak_count = 0   # Number of peaks with more than one match\n",
    "    \n",
    "    m_sorted = sorted(matches, key=lambda x: x.Pk_index)\n",
    "    m_grps = groupby(m_sorted, lambda x: x.Pk_index)\n",
    "    \n",
    "    for k, grp in m_grps:\n",
    "        \n",
    "        # to get the group as a list sorted by the length of the label use the following\n",
    "#       grp_as_list = sorted(list(grp), key= lambda x: len(x[1].Label))\n",
    "        \n",
    "        # get the group as a list sorted by absolute error\n",
    "        grp_as_list = sorted(list(grp), key= lambda x: abs(x.Error))\n",
    "\n",
    "        if len(grp_as_list) > 1:\n",
    "            redundant += grp_as_list\n",
    "            redundant_peak_count += 1\n",
    "        \n",
    "    return redundant_peak_count, redundant\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unmatched_indices(matched_indices, peaks, threshold):\n",
    "    \"\"\"\n",
    "    Find the indices of unmatched peaks that exceed a threshold\n",
    "    \"\"\"    \n",
    "    # get a boolean list indicating which peak is matched\n",
    "    peak_matches = [True if i in matched_indices else False for i in range(len(peaks))]\n",
    "    \n",
    "    # now find which ones ae false\n",
    "    unmatched = [i for i in range(len(peaks)) if not peak_matches[i]]\n",
    "    \n",
    "    return [i for i in unmatched if peaks[i].Inten >= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_matches_to_file(out_path, matches_to_save, peaks, conditions, match_conditions, with_details=False):\n",
    "    \"\"\"\n",
    "    Save the list of matches to a file. We use one of the print functions to do this\n",
    "    \"\"\"\n",
    "    with open(out_path, 'w') as f: \n",
    "        \n",
    "        # combine the conditions and match conditions in a single string\n",
    "        match_conds_str = ';'.join(match_conditions)\n",
    "        \n",
    "        if conditions:\n",
    "            conds =  ';'.join([conditions.rstrip(), match_conds_str])\n",
    "        else:\n",
    "            conds = match_conds_str\n",
    "\n",
    "        print(conds, file=f)\n",
    "            \n",
    "        if with_details:\n",
    "            print(match_with_tabs_header(), file=f)\n",
    "            for m in matches_to_save:         \n",
    "                print(match_as_str_with_tabs(m, peaks), file=f)\n",
    "        else:\n",
    "            print(match_short_with_tabs_header(), file=f)\n",
    "            for m in matches_to_save: \n",
    "                print(match_as_short_str_with_tabs(m, peaks), file=f)\n",
    "                \n",
    "        f.close()\n",
    "\n",
    "    return(len(to_save))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that convert a match to various output strings\n",
    "def match_as_str(m, peaks):\n",
    "    \"\"\"\n",
    "    Prettified string for printing in a Notebook cell\n",
    "    \"\"\"    \n",
    "    p_index, ion, mono_pk, error = m         # Unpack the peak index and the matching composition\n",
    "    p = peaks[p_index]       # peak mass and intensity\n",
    "    \n",
    "    error = error * 1000   # error in mmu   \n",
    "    \n",
    "    return f'{p_index:5}:{p.Mass:10.4f} ({error:5.1f}) {p.RT:6.2f} {p.Inten:12.1f} {ion.Mass:10.4f} {mono_pk:6}  {ion.Root:14}{ion.Label}'\n",
    "\n",
    "def match_as_str_with_tabs(m, peaks):\n",
    "    \"\"\"\n",
    "   Tab delimited detailed string.\n",
    "    \"\"\"    \n",
    "    p_index, ion, mono_pk, error   = m       # Unpack the peak index and the matching composition\n",
    "    p = peaks[p_index]       # peak mass and intensity\n",
    "    \n",
    "    error = error * 1000   # error in mmu   \n",
    "        \n",
    "    return f'{p.Mass:.4f}\\t{p.Inten:.1f}\\t{error:.1f}\\t{p.RT:.1f}\\t{p_index}\\t{mono_pk}\\t{ion.Mass:.4f}\\t{ion.Root:12}\\t{ion.Label}' \n",
    "\n",
    "def match_with_tabs_header():\n",
    "    \n",
    "    return \"Pk_mass\\tPk_inten\\tDelta_mmu\\tPk_RT\\tPk_index\\tMono__pk\\tMatch_mass\\tMatch_root\\tMatch_label\"\n",
    "\n",
    "def match_as_short_str(m, peaks):\n",
    "    \"\"\"\n",
    "    Simplified pretty string\n",
    "    \"\"\"\n",
    "    p_index, ion, mono_pk, error = m         # Unpack the peak index and the matching composition\n",
    "    p = peaks[p_index]       # peak mass and intensity\n",
    "        \n",
    "    return f'{p.Mass:10.4f} {p.Inten:12.1f} {p.RT:6.2f} {ion.Root} {ion.Label}'\n",
    "\n",
    "def match_as_short_str_with_tabs(m, peaks):\n",
    "    \"\"\"\n",
    "    Tab delimited mass and intensity for use elsewhere\n",
    "    \"\"\"\n",
    "    p_index, ion, mono_pk, error = m         # Unpack the peak index and the matching composition\n",
    "    p = peaks[p_index]       # peak mass and intensity\n",
    "        \n",
    "    return f'{p.Mass:.4f}\\t{p.Inten:.1f}\\t{p.RT:.2f}\\t{ion.Root}\\t{ion.Label}'\n",
    "\n",
    "def match_short_with_tabs_header():\n",
    "    \n",
    "    return \"Pk_mass\\tPk_inten\\tRT\\tRoot\\tMatch_label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_match_list(matches, peaks, print_fn, simplify=False):    \n",
    "    \"\"\"\n",
    "    Use the provided print function (e.g. match_as_str) to print the matches provided\n",
    "    If simplify == True, we only print one entry and append a string to indicate there are more\n",
    "    If group_first is True, we group the results by 'Root' before printing\n",
    "    \"\"\"\n",
    "    m_sorted = sorted(matches, key=lambda x: x.Pk_index)\n",
    "    m_grps = groupby(m_sorted, lambda x: x.Pk_index)     # group by peak index...groups with more than one entry have redundancy\n",
    "    \n",
    "    for k, grp in m_grps:\n",
    "        \n",
    "        # get the group as a list sorted by absolute error\n",
    "        grp_as_list = sorted(list(grp), key= lambda x: abs(x.Error))\n",
    "\n",
    "        \n",
    "        simplifying = simplify and (len(grp_as_list) > 1)   # do we need to simplify the output?\n",
    "        for g in grp_as_list:\n",
    "   \n",
    "            desc = print_fn(g, peaks)   \n",
    "                \n",
    "            if simplifying:\n",
    "                desc += f' [1/{len(grp_as_list)}]'\n",
    "            \n",
    "            print(desc)\n",
    "            \n",
    "            if simplifying: break  #only print one line\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a utility function to help sort peak lists\n",
    "def get_peak_mass_from_match(m, peaks):    \n",
    "    return peaks[m.Pk_index].Mass\n",
    "\n",
    "def get_count_and_tic(grp, peaks):\n",
    "    \"\"\"\n",
    "    Given a group of matches determine the number of unique peaks and the sum of the intensity they explain\n",
    "    \"\"\"\n",
    "    \n",
    "    last_index = 0\n",
    "    count = 0\n",
    "    tic = 0\n",
    "    \n",
    "    for m in grp:\n",
    "        \n",
    "        if m.Pk_index == last_index: continue\n",
    "        \n",
    "        last_index = m.Pk_index\n",
    "        \n",
    "        count += 1\n",
    "        tic += peaks[last_index].Inten\n",
    "        \n",
    "    return count, tic\n",
    "    \n",
    "def print_root_groups(matches, peaks, print_fn, suppress_isotopes=False, suppress_print=False):    \n",
    "    \"\"\"\n",
    "    Use the provided print function (e.g. match_as_str) to print the matches provided\n",
    "    We group the matches by the root first and sort by mass; if suppress_isotopes is True we skip\n",
    "    isotope matches (i.e. those where the Pk_index and MonoPeak are different)\n",
    "    Also returns a dictionary of group:(count, tic) that summarizes each group\n",
    "    \"\"\"\n",
    "    \n",
    "    r_sorted = sorted(matches, key=lambda x: x.TargetIon.Root)\n",
    "    r_grps = groupby(r_sorted, lambda x: x.TargetIon.Root)     # group by target root\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for k, grp in r_grps:\n",
    "        \n",
    "        # get the group as a list sorted by length of mass\n",
    "        grp_as_list = sorted(list(grp), key= lambda x: get_peak_mass_from_match(x, peaks))\n",
    "    \n",
    "        count, tic = get_count_and_tic(grp_as_list, peaks)\n",
    "        \n",
    "        if not suppress_print:\n",
    "            \n",
    "            # we can suppress isotopes by only selecting matches where the peak index and mono peak index are the same\n",
    "            if suppress_isotopes:  \n",
    "                grp_as_list = [m for m in grp_as_list if m.Pk_index == m.MonoPeak]\n",
    "            \n",
    "            for g in grp_as_list:          \n",
    "                print(print_fn(g, peaks))\n",
    "         \n",
    "            print()    # blank line after each group       \n",
    "        \n",
    "        result[k] = (count, tic)\n",
    "      \n",
    "    return result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a list of limits, i.e. (comp, max count) tuples, to a string\n",
    "# skip any with max_count = 0 and join the rest with commas\n",
    "def limits_as_string(limits):\n",
    "    non_zero_limits = [l for l in limits if l[1] > 0]\n",
    "    if len(non_zero_limits) == 0:\n",
    "        return \"\"\n",
    "    else:\n",
    "        desc = \",\".join([f'{l}' for l in non_zero_limits])\n",
    "        return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the conditions line and print each part on a separate line..\n",
    "def print_conditions(ion_file, conds_line):\n",
    "    \n",
    "    print(ion_file)\n",
    "    \n",
    "    parts = conds_line.split(';')\n",
    "    \n",
    "    for p in parts:\n",
    "        print(p.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Setup\n",
    "\n",
    "Define paths to the peak list and target ion list. Here we use a directory that is shared with the calculator to facilitate interactive use (we can run the calculator notebook, switch to one this and re-run it to see the changes). The code tests to see if we are using CoLab and, if so, mounts a GDrive and points a data_path at it.\n",
    "\n",
    "The lines marked 'UPDATE!' must be changed to relect the local environment. Windows users need to specify the disk, i.e.\n",
    "\n",
    "       data_path = 'C:' + os.sep + os.path.join('Users','ronbonner','Data', 'SharedData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using Colab\n",
      "/Users/ronbonner/Data/SharedData\n"
     ]
    }
   ],
   "source": [
    "# Define the path for data files; this allows the Calculator and Match notebooks to easily share data\n",
    "# We check for Colab and either use a GDrive directory or a local one\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    \n",
    "    print('Using Colab')\n",
    "    \n",
    "    drive.mount('/content/drive')   #  This is user-independent\n",
    "\n",
    "    data_path = os.sep + os.path.join('content', 'drive', 'MyDrive', 'SharedData')     # UPDATE!\n",
    "except:\n",
    "    print('Not using Colab')\n",
    "    data_path = os.sep + os.path.join('Users','ronbonner','Data', 'SharedData')      # UPDATE!\n",
    "\n",
    "print(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_matches = True                # do we want to save the matched peaks (as mass, inten, match name)?\n",
    "local_files = False\n",
    "include_large_unmatched = False      # do we want to include the larger unmatched peaks (by default > 1% base peak inten)\n",
    "include_date_in_file_name = False\n",
    "\n",
    "# the match window can be in amu or ppm (relative to mass); if both are speciefied the larger (at any mass) is used\n",
    "amu_window = 0.005     # amu half window for peak matching\n",
    "ppm_window = 20        # ppm half window for peak matching\n",
    "\n",
    "# We only look for the 13C isotopes of matched peaks\n",
    "c13_half_window = 0.003     # for matching 13C isotopes\n",
    "max_C13_count = 4           # maximum number of 13C's to look for\n",
    "c13_rt_window = 0.2         # main matched peaks and isotopes must have RTs that differ by less than this\n",
    "require_lower_c13_inten = True  # if True, potential isotope peaks must have a lower intensity than the matched peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 0 Int: 2 RT: 1\n",
      "/Users/ronbonner/Data/SharedData/200325 SJ C18 Pos A, C001-U.txt\n",
      "540, peaks read. TIC 372780.1, base peak inten 49781.4 has rt\n"
     ]
    }
   ],
   "source": [
    "# Read the peak file\n",
    "\n",
    "peak_file = '200325 SJ C18 Pos A, C001-U.txt'\n",
    "peak_file_path = peak_file if local_files else os.path.join(data_path, peak_file)\n",
    "\n",
    "peaks, tic, base_peak_inten, has_RT = read_peak_list(peak_file_path)\n",
    "\n",
    "rt_str = \"has rt\" if has_RT else \"\"\n",
    "\n",
    "print(peak_file_path)\n",
    "print(f'{len(peaks)}, peaks read. TIC {tic:.1f}, base peak inten {base_peak_inten} {rt_str}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ronbonner/Data/SharedData/Ibu ions pos 1.txt\n",
      "360 target ions read\n",
      "Ibu ions pos 1.txt\n",
      "Time:201208_092529\n",
      "Compounds:Ibu\n",
      "Multimer_limit:3\n",
      "Polarity:positive\n",
      "Phase_1:('OH', 2),('COOH', 1)\n",
      "Phase_2:('gluc', 1)\n",
      "Adducts:('Na-H', 2),('K-H', 2)\n",
      "Max adduct count:6\n",
      "Losses:('H2O', 1)\n"
     ]
    }
   ],
   "source": [
    "# Read the target ion file\n",
    "\n",
    "ion_file =  'Ibu ions pos 1.txt'   #\n",
    "compounds_as_string = 'Ibu'\n",
    "\n",
    "ion_path = ion_file if local_files else os.path.join(data_path, ion_file)\n",
    "\n",
    "ions, conditions = read_ion_list(ion_path)\n",
    "\n",
    "print(ion_path)\n",
    "\n",
    "print(f'{len(ions)} target ions read')\n",
    "\n",
    "if conditions:\n",
    "    print_conditions(ion_file, conditions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Match ions\n",
    "\n",
    "We first match the ions generated by the calculator. In a subsequent step we look specifically for the 13C forms of matched peaks.\n",
    "\n",
    "The code allows for the possibility that any peak may match multiple targets, and any target may be matched by multple peaks. This is can occur if retention times are present (e.g. if there are isomers at different RT), if there are very close masses (e.g. from very high resolution data) or if there are many close target ions generated from complex sets of adducts, losses, heterodimers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 peaks matched (21.5% tic), 82 total matches from 540 peaks\n"
     ]
    }
   ],
   "source": [
    "# Get the current time for use in the peak name and conditions\n",
    "current_time = datetime.datetime.now().replace(microsecond=0)\n",
    "curr_time_str = current_time.strftime('%y%m%d_%H%M%S')\n",
    "\n",
    "peak_index, ion_index, peaks_matched = 0, 0, 0\n",
    "\n",
    "matches = []   # this is going to end up as a list of Match tuples : (peak index, matched target)\n",
    "\n",
    "# Loop all the values and peaks looking for matches within the specified window\n",
    "while (ion_index < len(ions)) and (peak_index < len(peaks)):\n",
    "\n",
    "    this_peak, this_ion = peaks[peak_index], ions[ion_index]\n",
    "    low_peak, high_peak = get_mass_limits(this_peak.Mass, amu_window, ppm_window)\n",
    "    \n",
    "    # Increment the ion index if its Mass is too low and the peak if it's too high\n",
    "    if this_ion.Mass < low_peak:\n",
    "        ion_index += 1\n",
    "        continue\n",
    "\n",
    "    if this_ion.Mass > high_peak:\n",
    "        peak_index += 1\n",
    "        continue\n",
    "\n",
    "    # save peak index and ion composition\n",
    "    # since there may be more than one peak that matches this ion value, we look ahead at the peaks\n",
    "    # using a separate index so the current peak can be used with the next ion value\n",
    "    # we also track the ions matched since some ions may have more than one matching peak\n",
    "    \n",
    "    matches.append(Match(peak_index, this_ion, peak_index, this_peak.Mass - this_ion.Mass))    # reference to peak, this composition and the monopeak (this one)\n",
    "    peaks_matched += 1   \n",
    "    \n",
    "    look_ahead = peak_index + 1\n",
    " \n",
    "    # look ahead at the peaks while they're still within the search window and add any matches to the list\n",
    "    while (look_ahead < len(peaks)):\n",
    "                \n",
    "        look_ahead_peak = peaks[look_ahead]\n",
    "        \n",
    "        if(look_ahead_peak.Mass - this_ion.Mass) > get_mz_window(this_peak.Mass, amu_window, ppm_window):\n",
    "            break\n",
    "            \n",
    "        matches.append(Match(look_ahead, this_ion, look_ahead, look_ahead_peak.Mass - this_ion.Mass))\n",
    "        look_ahead +=1\n",
    "        peaks_matched += 1 \n",
    "\n",
    "\n",
    "    ion_index += 1 # increment ion index but not peak_index - there may be more than one ion within the window..\n",
    "\n",
    "matched_indices, percent_tic_matched = get_match_stats(matches, peaks, tic)\n",
    "\n",
    "matched_indices = sorted(matched_indices)\n",
    "initial_matches = f'{len(matched_indices)} peaks matched ({percent_tic_matched:.1f}% tic), {len(matches)} total matches from {len(peaks)} peaks'\n",
    "print(initial_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 peaks matched (26.9% tic), 126 total matches from 540 peaks\n"
     ]
    }
   ],
   "source": [
    "# Look for C13 isotopes of matched peaks\n",
    "# In addition to looking for mass deltas of 1.003, we test that the retention time differences are within a specified tolerance\n",
    "# we can always apply this test since missing RTs are stored as zero so the delta is guaranteed to be less than any positive, non-zero tolerance\n",
    "# We can optionally require that the intensity of isotope peaks be less than the initial matched peak\n",
    "# We look at the peak indices since we only need to test a peak once, even if it has multiple matches\n",
    "\n",
    "c13_matches = []\n",
    "\n",
    "last_matched_mass = 0\n",
    "last_peak_index = -1\n",
    "\n",
    "# make sure the peaks are in peak (= mass) order\n",
    "matches = sorted(matches, key=lambda x: x.Pk_index)\n",
    "\n",
    "for m in matches:    \n",
    "        \n",
    "    if m.Pk_index == last_peak_index:    #only need to look at each peak once\n",
    "        continue\n",
    "\n",
    "    peak_index = m.Pk_index    \n",
    "    last_peak_index = peak_index\n",
    "        \n",
    "    m_mass, m_inten, m_rt = peaks[peak_index]     # get the matched peak...\n",
    "    \n",
    "    next_peak_index = peak_index      #...and start looking for isotopes at the next higher peak\n",
    "        \n",
    "    keep_going = True\n",
    "    \n",
    "    for c13_count in range(1, max_C13_count+1):  #look for 1,2,3... C13\n",
    "    \n",
    "        c13_mass = m_mass + (c13_count * 1.003)   # expected c13 mass\n",
    "        c13_name = f'{m_mass:.4f}(+{c13_count})'  # name is based on mono mass with (+1) etc apended\n",
    "        \n",
    "        while next_peak_index < len(peaks) - 1:   # -1 since we're going to increment it\n",
    "            \n",
    "            next_peak_index += 1  # point at next value in peak list\n",
    "                \n",
    "            next_peak_mass, next_peak_inten, next_peak_rt = peaks[next_peak_index]\n",
    "            \n",
    "            # mass is out of range  \n",
    "            if next_peak_mass > (c13_mass + c13_half_window):\n",
    "                keep_going = False       # when one isotope is not matched we abort and stop looking for more\n",
    "                break\n",
    "            \n",
    "            # if the mass is in range we also check that the RT is within a window...\n",
    "            # Note: it's OK to always apply this test since if there is no RT the values will be zero\n",
    "            # and therefore the delta will be less than the threshold\n",
    "            rt_ok = abs(m_rt-next_peak_rt)< c13_rt_window\n",
    "            \n",
    "            inten_ok = True if require_lower_c13_inten else next_peak_inten < m_inten\n",
    "            \n",
    "            if next_peak_mass > (c13_mass - c13_half_window) and rt_ok and inten_ok:\n",
    "                c13 = Target(c13_mass, m.TargetIon.Root, c13_name)\n",
    "                c13_matches.append(Match(next_peak_index, c13, peak_index, next_peak_mass - c13_mass))\n",
    "                break     # and look for the next higher isotope\n",
    "        \n",
    "        if not keep_going:\n",
    "            break     # leave 13c for loop   \n",
    "\n",
    "matches += c13_matches\n",
    "\n",
    "matches = sorted(matches, key = lambda x: x.Pk_index)  # sort by peak index...\n",
    "\n",
    "matched_indices, percent_tic_matched = get_match_stats(matches, peaks, tic)\n",
    "\n",
    "after_13c_match = f'{len(matched_indices)} peaks matched ({percent_tic_matched:.1f}% tic), {len(matches)} total matches from {len(peaks)} peaks'\n",
    "print(after_13c_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Print, review, save\n",
    "\n",
    "Cells illustrate various ways to report the matches:\n",
    "\n",
    "- print all or some of them inside the notebook; there is an option to show all matches, including redundant ones, or to simplify the output to only show the shortest\n",
    "- count the number of peaks that have redundant matches and optionally print them\n",
    "- print the unmatched peaks above a thershold (as percentage of the base peak intensity)\n",
    "\n",
    "Reviewing redundant peaks is useful as it can indicate that parameters need changing (if there are too many), for example: reduce the matching tolerance, reduce the number of target ions, etc.\n",
    "\n",
    "The unmatched peak list is a good way to find peaks that still need to be explained and is the first step in further interpretation.\n",
    "\n",
    "The detailed list os matched can be written to a file for use with the Interpret module or elsewhere and a final cell summarizes the parameters and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 peaks matched (26.9% tic), 126 total matches from 540 peaks\n",
      "   38:  205.1219 ( -0.4)   8.36        403.2   205.1223     38  Ibu_OH        Ibu_OH-H2O.H+\n",
      "   39:  205.1220 ( -0.3)   6.80        468.7   205.1223     39  Ibu_OH        Ibu_OH-H2O.H+\n",
      "   40:  205.1220 ( -0.3)   7.60       1715.0   205.1223     40  Ibu_OH        Ibu_OH-H2O.H+\n",
      "   41:  206.1253 (  0.4)   8.36         55.9   206.1249     38  Ibu_OH        205.1219(+1)\n",
      "   42:  206.1256 (  0.6)   7.60        267.9   206.1250     40  Ibu_OH        205.1220(+1)\n",
      "   46:  207.1376 ( -0.4)   8.71        717.5   207.1380     46  Ibu           Ibu.H+\n",
      "   50:  208.1406 (  0.0)   8.71         77.5   208.1406     46  Ibu           207.1376(+1)\n",
      "   54:  219.1010 ( -0.6)   7.65        618.4   219.1016     54  Ibu_COOH      Ibu_COOH-H2O.H+\n",
      "   55:  219.1011 ( -0.5)   6.27        121.9   219.1016     55  Ibu_COOH      Ibu_COOH-H2O.H+\n",
      "   56:  221.1172 (  0.0)   6.09         40.4   221.1172     56  Ibu_(OH)2     Ibu_(OH)2-H2O.H+\n",
      "   57:  221.1173 (  0.1)   5.18         22.5   221.1172     57  Ibu_(OH)2     Ibu_(OH)2-H2O.H+\n",
      "   58:  221.1173 (  0.1)   7.22         73.5   221.1172     58  Ibu_(OH)2     Ibu_(OH)2-H2O.H+\n",
      "   61:  223.1329 (  0.0)   7.82        279.9   223.1329     61  Ibu_OH        Ibu_OH.H+\n",
      "   62:  223.1330 (  0.1)   6.29       2686.7   223.1329     62  Ibu_OH        Ibu_OH.H+\n",
      "   63:  224.1363 (  0.3)   6.27        508.6   224.1360     62  Ibu_OH        223.1330(+1)\n",
      "   74:  229.1197 ( -0.2)  11.56         48.9   229.1199     74  Ibu           Ibu.Na-H.H+\n",
      "   78:  237.1124 (  0.3)   6.27        199.0   237.1121     78  Ibu_COOH      Ibu_COOH.H+\n",
      "   89:  245.1149 (  0.1)   7.80       2956.2   245.1148     89  Ibu_OH        Ibu_OH.Na-H.H+\n",
      "   90:  246.1184 (  0.5)   7.82        479.6   246.1179     89  Ibu_OH        245.1149(+1)\n",
      "   95:  249.0858 ( -0.4)  10.85         41.0   249.0862     95  Ibu_OH        Ibu_OH-H2O.(Na-H)2.H+\n",
      "   98:  251.1021 (  0.2)  11.56        869.4   251.1019     98  Ibu           Ibu.(Na-H)2.H+\n",
      "   99:  252.1055 (  0.4)  11.56        147.2   252.1051     98  Ibu           251.1021(+1)\n",
      "  101:  253.1076 ( -0.5)  11.56         11.9   253.1081     98  Ibu           251.1021(+2)\n",
      "  111:  259.0942 (  0.1)   7.63       4757.8   259.0941    111  Ibu_COOH      Ibu_COOH.Na-H.H+\n",
      "  112:  260.0969 ( -0.3)   7.63        800.4   260.0972    111  Ibu_COOH      259.0942(+1)\n",
      "  115:  261.0886 ( -0.2)   7.82        359.2   261.0888    115  Ibu_OH        Ibu_OH.K-H.H+\n",
      "  116:  261.1100 (  0.2)   6.09        493.9   261.1098    116  Ibu_(OH)2     Ibu_(OH)2.Na-H.H+\n",
      "  117:  262.1130 (  0.0)   6.09         74.0   262.1130    116  Ibu_(OH)2     261.1100(+1)\n",
      "  122:  267.0760 (  0.2)  11.56        102.1   267.0758    122  Ibu           Ibu.Na-H.K-H.H+\n",
      "  123:  267.0962 ( -0.6)   8.36        124.0   267.0968    123  Ibu_OH        Ibu_OH.(Na-H)2.H+\n",
      "  124:  267.0970 (  0.2)   7.80       1084.8   267.0968    124  Ibu_OH        Ibu_OH.(Na-H)2.H+\n",
      "  125:  268.0786 ( -0.4)  11.58         14.1   268.0790    122  Ibu           267.0760(+1)\n",
      "  135:  275.0673 ( -0.7)   7.65        515.7   275.0680    135  Ibu_COOH      Ibu_COOH.K-H.H+\n",
      "  141:  281.0754 ( -0.6)   7.65        549.2   281.0760    141  Ibu_COOH      Ibu_COOH.(Na-H)2.H+\n",
      "  142:  282.0797 (  1.3)   7.63         76.1   282.0784    141  Ibu_COOH      281.0754(+1)\n",
      "  143:  283.0708 (  0.1)   7.82         79.5   283.0707    143  Ibu_OH        Ibu_OH.Na-H.K-H.H+\n",
      "  144:  283.0914 ( -0.3)   6.09         58.2   283.0917    144  Ibu_(OH)2     Ibu_(OH)2.(Na-H)2.H+\n",
      "  148:  289.0528 ( -4.9)   0.75         53.9   289.0577    148  Ibu           Ibu.(Na-H)2.K-H.H+\n",
      "  222:  365.1598 (  0.3)   9.14       4822.7   365.1595    222  Ibu_gluc      Ibu_gluc-H2O.H+\n",
      "  223:  366.1631 (  0.3)   9.14       1240.8   366.1628    222  Ibu_gluc      365.1598(+1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the matches for review. To print a few matches use, for example, matches[:40]\n",
    "# If there are redundant matches (i.e. more than one match for a peak) they are sorted by length, the idea being that that the simplest is more likely.\n",
    "# If 'simplify' is True, only the first label (shortest) is printed with a notation indicating that there are others\n",
    "\n",
    "print(after_13c_match)\n",
    "print_match_list(matches[:40], peaks, match_as_str, simplify=True)  # remove '40' to see all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ibu         \tcount:  14\tinten sum       2415.8,   0.6% tic\n",
      "Ibu_(OH)2   \tcount:   8\tinten sum        939.8,   0.3% tic\n",
      "Ibu_(OH)2_gluc\tcount:  10\tinten sum       1709.4,   0.5% tic\n",
      "Ibu_COOH    \tcount:  15\tinten sum      11477.1,   3.1% tic\n",
      "Ibu_COOH_gluc\tcount:  10\tinten sum       4791.7,   1.3% tic\n",
      "Ibu_OH      \tcount:  19\tinten sum      12818.4,   3.4% tic\n",
      "Ibu_OH_gluc \tcount:  28\tinten sum      36494.5,   9.8% tic\n",
      "Ibu_gluc    \tcount:  22\tinten sum      30179.9,   8.1% tic\n"
     ]
    }
   ],
   "source": [
    "# We can also organize the matches by root before printing..\n",
    "# Theh matches re sorted in peak (mass) order and isotopes can be skipped by seeting suppres_isotopes = True\n",
    "# print_root_groups returns a dictionary which summarizes the results for each root group\n",
    "#\n",
    "# i.e. number of members, intensity and percent tic...if suppress_print is true we just get the diictionary\n",
    "# if suppress_print is true the peaks are not printed and only the summary dictinary is reurned\n",
    "\n",
    "grp_stats = print_root_groups(matches, peaks, match_as_str, suppress_isotopes = False, suppress_print=True)\n",
    "\n",
    "for g in grp_stats:\n",
    "    count, int_sum = grp_stats[g]\n",
    "    percent_tic = int_sum * 100 / tic\n",
    "    print(f'{g:12}\\tcount:{count:4}\\tinten sum {int_sum:12.1f}, {percent_tic:5.1f}% tic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  redundant peaks have 8 matches\n"
     ]
    }
   ],
   "source": [
    "# It can be useful to review the redundant matches, i.e. peaks that have multiple matches, since these can indicate adduct/loss/modifcation combinations\n",
    "# that result in the same mass suggesting opprotunities to simplify the lists\n",
    "\n",
    "redundant_peak_count, redundant_matches = get_redundant_matches(matches)\n",
    "\n",
    "print(redundant_peak_count,' redundant peaks have', len(redundant_matches), 'matches')\n",
    "\n",
    "print_redundant_matches = False\n",
    "\n",
    "# To make the list easier to read, we add a blank line between the redundant groups\n",
    "if print_redundant_matches:\n",
    "    \n",
    "    last_index = -1\n",
    "    for m in redundant_matches:\n",
    "        if m.Pk_index != last_index:   # when the Pk_index changes...\n",
    "            print()\n",
    "            last_index = m.Pk_index\n",
    "            \n",
    "        print(match_as_str(m, peaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  177.1270     6.29        643     1.29% base peak\n",
      "  222.1490     7.60        812     1.63% base peak\n",
      "  224.1642     8.73       4248     8.53% base peak\n",
      "  225.1675     8.71        756     1.52% base peak\n",
      "  240.1594     7.62       8318    16.71% base peak\n",
      "  241.1628     7.60       1775     3.57% base peak\n",
      "  248.1494     2.01       1128     2.27% base peak\n",
      "  254.1389     7.63      13349    26.81% base peak\n",
      "  255.1422     7.63       2751     5.53% base peak\n",
      "  256.1545     6.09        989     1.99% base peak\n",
      "  258.1526     5.59        912     1.83% base peak\n",
      "  350.2329     8.32       2709     5.44% base peak\n",
      "  351.2363     8.32        748     1.50% base peak\n",
      "  363.1441     6.98        735     1.48% base peak\n",
      "  363.1441     6.16       3500     7.03% base peak\n",
      "  364.1480     6.16        832     1.67% base peak\n",
      "  398.1805     8.25       3355     6.74% base peak\n",
      "  398.9490     8.71        599     1.20% base peak\n",
      "  399.1840     8.25        998     2.00% base peak\n",
      "  400.1965     8.73      45550    91.50% base peak\n",
      "  401.2003     8.73      16401    32.95% base peak\n",
      "  402.2022     8.73       3569     7.17% base peak\n",
      "  407.2394     1.27       2276     4.57% base peak\n",
      "  408.2428     1.27        578     1.16% base peak\n",
      "  414.8938     6.18        621     1.25% base peak\n",
      "  416.1917     6.18      49781   100.00% base peak\n",
      "  416.1922     6.78      11999    24.10% base peak\n",
      "  417.1960     6.18      16606    33.36% base peak\n",
      "  417.1965     6.78       3549     7.13% base peak\n",
      "  418.1972     6.78        667     1.34% base peak\n",
      "  418.1979     6.16       3601     7.23% base peak\n",
      "  430.1714     6.26      20965    42.11% base peak\n",
      "  431.1752     6.26       5757    11.56% base peak\n",
      "  432.1763     6.26       1221     2.45% base peak\n",
      "  432.1869     5.16       2326     4.67% base peak\n",
      "  433.1907     5.18        656     1.32% base peak\n",
      "  535.2740     5.59       1516     3.04% base peak\n",
      "  562.2488     8.08       3079     6.18% base peak\n",
      "  562.2497     9.07       1098     2.21% base peak\n",
      "  563.2526     8.08       1026     2.06% base peak\n",
      "  775.2652     7.65        700     1.41% base peak\n",
      "  814.3496     6.18        690     1.39% base peak\n",
      "  828.3260     6.27        500     1.00% base peak\n",
      "43 unmatched Largest unmatched 416.1917, 49781.4 100.0% base\n"
     ]
    }
   ],
   "source": [
    "# It is useful to print the largest unmatched peaks since these suggest opportunities to modify the Calculator parameters\n",
    "# to get greater coverage. Some peaks may be easy to explain (unusual isotopes, obvious losses, etc.)\n",
    "# Unexplained, large peaks can be included in the Calculator, for example,  ('x544', 544.2148) was included in the Ibuprofen compound\n",
    "# list to explain ions at 562 and 567 corresponding to X+NH4+ and X+Na+\n",
    "\n",
    "threshold_percent = 1   #default threshold\n",
    "\n",
    "bpi_percent_thresh = threshold_percent * base_peak_inten / 100   # convert to counts\n",
    "\n",
    "unmatched_indices = get_unmatched_indices(matched_indices, peaks, bpi_percent_thresh)  # get the unmatched peask > 1% base peak\n",
    "\n",
    "unmatched_mass, largest_unmatched_inten = 0,0\n",
    "\n",
    "for pi in unmatched_indices:\n",
    "    m,inten,rt = peaks[pi]\n",
    "    percent_base_peak = inten * 100/ base_peak_inten\n",
    "    print(f'{m:10.4f} {rt:8.2f} {inten:10.0f} {percent_base_peak:8.2f}% base peak')\n",
    "    \n",
    "    if inten > largest_unmatched_inten:\n",
    "        unmatched_mass, largest_unmatched_inten = m,inten\n",
    "\n",
    "large_inten_rel = largest_unmatched_inten * 100/ base_peak_inten\n",
    "\n",
    "largest_unmatched_string = f'Largest unmatched {unmatched_mass}, {largest_unmatched_inten} {large_inten_rel:.1f}% base'\n",
    "\n",
    "print(len(unmatched_indices), 'unmatched', largest_unmatched_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make a list of strings containing the match conditions so they can be saved to the ouput files\n",
    "# and printed (below)\n",
    "match_conditions = [f'Match time: {curr_time_str}']\n",
    "match_conditions.append(f'Peaks file: {peak_file_path}, {len(peaks)} peaks')\n",
    "match_conditions.append(f'Matching amu half window: {amu_window}')\n",
    "match_conditions.append(f'Matching ppm half window: {ppm_window} ppm')\n",
    "\n",
    "match_conditions.append(f'Looking for <= {max_C13_count} 13C isotopes with half window {c13_half_window}')\n",
    "\n",
    "match_conditions.append(initial_matches)\n",
    "match_conditions.append(f'After 13C match {after_13c_match}')\n",
    "\n",
    "match_conditions.append(f'{len(unmatched_indices)} unmatched peaks gt {threshold_percent}%, {largest_unmatched_string}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ronbonner/Data/SharedData/200325 SJ C18 Pos A, C001-U Ibu matches.txt\n",
      "126  lines written\n"
     ]
    }
   ],
   "source": [
    "# Save the match list if needed\n",
    "# Note: The peak_file_path will already reflect the setting of 'local_files' so we don't need to test it again\n",
    "# The code allows the largest unmatched peaks to be included if desired by creating empty matches for them\n",
    "if save_matches:\n",
    "\n",
    "    out_path, _ = os.path.splitext(peak_file_path)    # path without extension\n",
    "\n",
    "    if include_date_in_file_name:\n",
    "        out_path = f'{out_path} {compounds_as_string} matches {curr_time_str}.txt'\n",
    "    else:\n",
    "         out_path = f'{out_path} {compounds_as_string} matches.txt'       \n",
    "    \n",
    "    to_save = matches\n",
    "    \n",
    "    # If we want the unmatched ions, we generate an empty Match tuple for each and append them to the actual matches\n",
    "    # Empty tuple has Pk_index, an empty target ion, the peak index is the mono peak, and an error of 0\n",
    "    if include_large_unmatched:\n",
    "        to_save = matches + [(i, Target(0,'', 'None'), i, 0) for i in unmatched_indices]\n",
    "    \n",
    "    to_save = sorted(to_save, key = lambda x: x[0])\n",
    "\n",
    "    lines_written_count = save_matches_to_file(out_path, to_save, peaks, conditions, match_conditions, with_details=True)\n",
    "    \n",
    "    print(out_path)\n",
    "    print(lines_written_count, ' lines written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-08 16:13:00\n",
      "360 targets\n",
      "Ibu ions pos 1.txt\n",
      "Time:201208_092529\n",
      "Compounds:Ibu\n",
      "Multimer_limit:3\n",
      "Polarity:positive\n",
      "Phase_1:('OH', 2),('COOH', 1)\n",
      "Phase_2:('gluc', 1)\n",
      "Adducts:('Na-H', 2),('K-H', 2)\n",
      "Max adduct count:6\n",
      "Losses:('H2O', 1)\n",
      "\n",
      "Match time: 201208_161300\n",
      "Peaks file: /Users/ronbonner/Data/SharedData/200325 SJ C18 Pos A, C001-U.txt, 540 peaks\n",
      "Matching amu half window: 0.005\n",
      "Matching ppm half window: 20 ppm\n",
      "Looking for <= 4 13C isotopes with half window 0.003\n",
      "80 peaks matched (21.5% tic), 82 total matches from 540 peaks\n",
      "After 13C match 122 peaks matched (26.9% tic), 126 total matches from 540 peaks\n",
      "43 unmatched peaks gt 1%, Largest unmatched 416.1917, 49781.4 100.0% base\n"
     ]
    }
   ],
   "source": [
    "# Finally we summarize the results\n",
    "\n",
    "print (current_time)\n",
    "\n",
    "print(len(ions), 'targets')\n",
    "\n",
    "if conditions:\n",
    "    print_conditions(ion_file, conditions)\n",
    "\n",
    "print()\n",
    "for mc in match_conditions:\n",
    "    print (mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
