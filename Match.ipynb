{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching 20201105\n",
    "\n",
    "Compares a target list of masses and labels with an experimental peak list. A target list based on specific compounds (including unknowns) and adducts can be calculated with 'CompounCalculator' or an external list, e.g. contaminants, can be used. It is often convenient to open the Calculator and Match notebooks in side-by-side windows (Jupyter Lab allows this) so it is easy to update the target ion list and repeat the matching.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The program matches the target ion and peak lists using a tolerance that can be specified in amu (fixed) or ppm (increases with mass). If both are non-zero the ppm is calulated and the larger window used which allows the window to increase with mass but never be less that a certain value. The program also allows for the possibility that complex peak and target ion lists can result in multiple matches for each peak. The function that prints the matches has a simplify mode which shows only one match for each peak but appends a string showing the number of matches; the match shown is the one with the smallest absolute error. Matched peaks can be grouped according to the 'root' field, which is part of the target ion list, and there is a cell that shows peaks with redundant matches to emphasize their existence and allow adjustment of the matching or ion generation parameters if necessary.\n",
    "\n",
    "Unmatched peaks greater than a given intensity threshold (percent base peak intensity) are also displayed. The idea is that this is part of interactive spectrum interpretation, i.e. once the origin of unmatched peaks is understood the ion generation parameters can be adjusted and applied to other peaks.\n",
    "\n",
    "In order to ensure that isotope peaks stay with the monoisotopic peaks, the program only searches for 13C peaks for matched peaks. Identified isotope peaks can also match entries in the target ion list so other possibilities are shown. In the output lists each peak has an index as well as the index of a related monoisotopic peak; these are the same for actual monoisotopic peaks.\n",
    "\n",
    "The peak list must be tab-delimited and have mass values but can also contain columns for Retention Time (RT) and Intensity; the function that reads the peak list tries to determine which columns are present.\n",
    "\n",
    "Results can be saved in several ways including a simple mass/intensity list and more detailed lists. Text lists can be imported into PeakView as spectra and overlaid on the original data to visualize the matches and highlight unmatched peaks.\n",
    "\n",
    "## Imports and function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime \n",
    "from collections import namedtuple, defaultdict\n",
    "from itertools import groupby\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some named tuples to hold the data and results\n",
    "Peak = namedtuple('Peak', 'Mass Inten RT')\n",
    "Target = namedtuple('Target', 'Mass Root Label')\n",
    "\n",
    "# a match contains the index of the peak, the calculated ion it matches, the index of the monoisotopic peak (if applicable) and the mass error\n",
    "# the latter fields allow the matched lists to be redily sorted and filtered\n",
    "Match = namedtuple('Match', 'Pk_index TargetIon MonoPeak Error')   \n",
    "\n",
    "MatchedPeak = namedtuple('MatchedPeak', 'Mass RT Inten TargetMass TargetLabel MonoPeak Error')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_from_line(line):\n",
    "    \"\"\"\n",
    "    Split a line into parts and try to convert them to numbers...return the list of numbers or fields\n",
    "    \"\"\"\n",
    "    \n",
    "    parts = line.split()\n",
    "    \n",
    "    try:\n",
    "        vals = [float(field) for field in parts]  # convert all to numbers\n",
    "        success = True\n",
    "    except:\n",
    "        vals = parts      # return the fields if the conversion fails\n",
    "        success = False\n",
    "    \n",
    "    return success, vals\n",
    "    \n",
    "    \n",
    "def read_peak_list(peak_file_path):\n",
    "    \"\"\"\n",
    "    Reads a tab-delimited text file generating a list of Peak tuples (Mass, Inten, RT). Mass must be present but the other fields are optional\n",
    "    and will be stored internally as zero if absent.\n",
    "    If the file has only one column it is assumed to contain masses otherwise the code assumes that the first column is Mass,\n",
    "    the second is Inten and the RT is absent.\n",
    "    If the file contains a header line it is used to define the order of the columns by looking for matches with common labels\n",
    "    e.g. mz, m/z, Mass, etc. for masses. The RT column can only be used via a header line containi 'RT' or 'rt'\n",
    "    \"\"\"\n",
    "    mass_col = 0\n",
    "    inten_col = 1\n",
    "    rt_col = -1\n",
    "    has_rt = False\n",
    "    has_inten = True\n",
    "    start_line= 0\n",
    "    \n",
    "    peaks = []    #list of (mass, inten, RT) tuples\n",
    "\n",
    "    # read all the lines so we can process them one-by-one\n",
    "    with open(peak_file_path, 'r') as f:  \n",
    "    \n",
    "        lines = f.readlines()\n",
    "        \n",
    "        f.close()\n",
    "    \n",
    "    success, vals = values_from_line(lines[0])  # try to convert the first line\n",
    "    \n",
    "    if not success:   # couldn't get values; probably a header....vals is a list of the parts\n",
    "\n",
    "        # see if we can figure out what the columns are...lsist can be extende if needed\n",
    "        for col_index, col in enumerate(vals):\n",
    "            if col in ['mz', 'm/z', 'mass', 'Mass', 'Mass/Charge']: mass_col = col_index\n",
    "            if col in ['Int', 'Inten', 'inten', 'Height']: inten_col = col_index\n",
    "            if col in ['RT', 'rt']: rt_col = col_index\n",
    "\n",
    "        has_rt = rt_col > -1\n",
    "        has_inten = inten_col > -1\n",
    "            \n",
    "        start_line = 1     # can skip this line\n",
    "\n",
    "#        print('m:', mass_col, 'Int:', inten_col, 'RT:', rt_col)\n",
    "        \n",
    "    base_peak_mass, base_peak_inten = 0,0\n",
    "\n",
    "    # Process line by line. Lines that cannot be converted to numbers are reported \n",
    "    # Note: the first line will be reprocessed if it is numeric\n",
    "    for line in lines[start_line:]:        \n",
    "\n",
    "        # get a list of numbers from the fields in the line - success will be false if this fails and vals will be the actual text parts\n",
    "        success, vals = values_from_line(line)  \n",
    "               \n",
    "        if success:\n",
    "            mass = vals[mass_col]\n",
    "            rt = vals[rt_col] if has_rt else 0\n",
    "            inten = vals[inten_col] if has_inten else 0\n",
    "            \n",
    "            p = Peak(mass, inten, rt)\n",
    "              \n",
    "            peaks.append(p)\n",
    "            \n",
    "            if inten > base_peak_inten:\n",
    "                base_peak_inten = inten\n",
    "                base_peak_mass = mass\n",
    "            \n",
    "        else:\n",
    "            print('Problem in line:', line, vals)   # vals will be the list of fields if there's a problem\n",
    "    \n",
    "    peaks = sorted(peaks, key = lambda x: x.Mass)     # ensure the list is sorted by mass\n",
    "\n",
    "    masses, intens, rts = zip(*peaks)\n",
    "\n",
    "    # Note: intensity params will be 0 if there is no intensity column\n",
    "    return peaks, sum(intens), base_peak_mass, base_peak_inten, has_rt    # peaks, tic, base_peak_inten, sum rts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ion_list(ion_file_path):\n",
    "    \"\"\"\n",
    "    Read the taget ion file which is assumed to contain fields for mass, root and label that can be converted to a Target\n",
    "    It may also contain a condiions line (indicated by '#'\n",
    "    \"\"\"\n",
    "    \n",
    "    ions = []            #list of (mass, root, label) tuples\n",
    "    cond_str = \"\"        # target file generation conditions line if present\n",
    "    \n",
    "    with open(ion_file_path, 'r') as f:  \n",
    "    \n",
    "        for line in f:\n",
    "            \n",
    "            if line[0] == '#':             # if the first character is '#' this is a condition line\n",
    "                cond_str = line[1:]\n",
    "                continue\n",
    "            \n",
    "            parts = line.split()\n",
    "            \n",
    "            # we try to parse each line as a float followed by 2 strings; if this fails we report it but carry on anyway\n",
    "            try:\n",
    "                ion = Target(float(parts[0]), parts[1], parts[2])\n",
    "                ions.append(ion) \n",
    "            except:\n",
    "                print('Problem in', line)\n",
    "\n",
    "        f.close()\n",
    "    \n",
    "    ions = sorted(ions, key = lambda x: x.Mass)     # ensure the list is sorted by mass\n",
    "\n",
    "    return ions, cond_str    # target ions and conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mz_window(mz, amu, ppm):\n",
    "    \"\"\"\n",
    "    Determine the mass window to use for matching either as ppm or amu.\n",
    "    If both are supplied the larger will be used; this allows the window to increase with mass (ppm) but\n",
    "    never be smaller than amu.\n",
    "    If either is zero, the other is automatically used    \n",
    "    \"\"\"\n",
    "    ppm_window = mz * ppm /1e6\n",
    "    \n",
    "    if ppm_window > amu:\n",
    "        return ppm_window\n",
    "    else:\n",
    "        return amu\n",
    "    \n",
    "def get_mass_limits(mz, amu, ppm):\n",
    "    \"\"\"\n",
    "    Uses get_mz_window to determine the window size and returns the upper an lower mass limits\n",
    "    \"\"\"\n",
    "    window = get_mz_window(mz, amu, ppm)\n",
    "    return mz - window, mz + window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_stats(matches, peaks, tic):\n",
    "    \"\"\"\n",
    "    Given lists of peaks and matches, returns the indices of the matched peaks and the percentage\n",
    "    of the TIC that they explain\n",
    "    \"\"\"\n",
    "\n",
    "    matched_indices = set([m.Pk_index for m in matches])   # get the peak indices; we uae a set so each peak occurs only once\n",
    "\n",
    "    matched_inten = sum([peaks[i].Inten for i in matched_indices])  # sum the intensities\n",
    "\n",
    "    percent_matched = matched_inten * 100/tic\n",
    "    \n",
    "    return matched_indices, percent_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redundant_matches(matches):\n",
    "    \"\"\"\n",
    "    Find which peaks have multiple matches.\n",
    "    We group the matches by peak index and then find which groups have more than one entry\n",
    "    We return the count and the redundant groups individually sorted by absolute error\n",
    "    \"\"\"\n",
    "    redundant = []\n",
    "    redundant_peak_count = 0   # Number of peaks with more than one match\n",
    "    \n",
    "    m_sorted = sorted(matches, key=lambda x: x.Pk_index)\n",
    "    m_grps = groupby(m_sorted, lambda x: x.Pk_index)\n",
    "    \n",
    "    for k, grp in m_grps:\n",
    "        \n",
    "        # to get the group as a list sorted by the length of the label use the following\n",
    "#       grp_as_list = sorted(list(grp), key= lambda x: len(x[1].Label))\n",
    "        \n",
    "        # get the group as a list sorted by absolute error\n",
    "        grp_as_list = sorted(list(grp), key= lambda x: abs(x.Error))\n",
    "\n",
    "        if len(grp_as_list) > 1:\n",
    "            redundant += grp_as_list\n",
    "            redundant_peak_count += 1\n",
    "        \n",
    "    return redundant_peak_count, redundant\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unmatched peaks above a given threshold, usually zero\n",
    "def get_unmatched_indices(matched_indices, peaks, threshold = 0.0):\n",
    "    \"\"\"\n",
    "    Find the indices of unmatched peaks that exceed a threshold\n",
    "    \"\"\"    \n",
    "    # get a boolean list indicating which peak is matched\n",
    "    peak_matches = [True if i in matched_indices else False for i in range(len(peaks))]\n",
    "    \n",
    "    # now find which ones ae false\n",
    "    unmatched = [i for i in range(len(peaks)) if not peak_matches[i]]\n",
    "    \n",
    "    return [i for i in unmatched if peaks[i].Inten >= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_matches_to_file(out_path, matches_to_save, peaks, target_conditions, match_conditions, with_details=False):\n",
    "    \"\"\"\n",
    "    Save the list of matches to a file. We use one of the print functions to do this\n",
    "    \"\"\"\n",
    "    with open(out_path, 'w') as f: \n",
    "        \n",
    "        # combine the target_conditions and match conditions in a single string\n",
    "        match_conds_str = ';'.join(match_conditions)\n",
    "        \n",
    "        if target_conditions:\n",
    "            conds =  ';'.join([target_conditions.rstrip(), match_conds_str])\n",
    "        else:\n",
    "            conds = match_conds_str\n",
    "\n",
    "        print(conds, file=f)\n",
    "            \n",
    "        if with_details:\n",
    "            print(match_with_tabs_header(), file=f)\n",
    "            for m in matches_to_save:         \n",
    "                print(match_as_str_with_tabs(m, peaks), file=f)\n",
    "        else:\n",
    "            print(match_short_with_tabs_header(), file=f)\n",
    "            for m in matches_to_save: \n",
    "                print(match_as_short_str_with_tabs(m, peaks), file=f)\n",
    "                \n",
    "        f.close()\n",
    "\n",
    "    return(len(to_save))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that convert a match to various output strings\n",
    "def match_as_str(m, peaks):\n",
    "    \"\"\"\n",
    "    Prettified string for printing in a Notebook cell\n",
    "    \"\"\"    \n",
    "    p_index, ion, mono_pk, error = m         # Unpack the peak index and the matching composition\n",
    "    p = peaks[p_index]       # peak mass and intensity\n",
    "    \n",
    "    error = error * 1000   # error in mmu   \n",
    "    \n",
    "    return f'{p_index:5}:{p.Mass:10.4f} ({error:5.1f}) {p.RT:6.2f} {p.Inten:12.1f} {ion.Mass:10.4f} {mono_pk:6}  {ion.Root:14}{ion.Label}'\n",
    "\n",
    "def match_as_str_with_tabs(m, peaks):\n",
    "    \"\"\"\n",
    "   Tab delimited detailed string.\n",
    "    \"\"\"    \n",
    "    p_index, ion, mono_pk, error   = m       # Unpack the peak index and the matching composition\n",
    "    p = peaks[p_index]       # peak mass and intensity\n",
    "    \n",
    "    error = error * 1000   # error in mmu   \n",
    "        \n",
    "    return f'{p.Mass:.4f}\\t{p.Inten:.1f}\\t{error:.1f}\\t{p.RT:.1f}\\t{p_index}\\t{mono_pk}\\t{ion.Mass:.4f}\\t{ion.Root:12}\\t{ion.Label}' \n",
    "\n",
    "def match_with_tabs_header():\n",
    "    \n",
    "    return \"Pk_mass\\tPk_inten\\tDelta_mmu\\tPk_RT\\tPk_index\\tMono__pk\\tMatch_mass\\tMatch_root\\tMatch_label\"\n",
    "\n",
    "def match_as_short_str(m, peaks):\n",
    "    \"\"\"\n",
    "    Simplified pretty string\n",
    "    \"\"\"\n",
    "    p_index, ion, mono_pk, error = m         # Unpack the peak index and the matching composition\n",
    "    p = peaks[p_index]       # peak mass and intensity\n",
    "        \n",
    "    return f'{p.Mass:10.4f} {p.Inten:12.1f} {p.RT:6.2f} {ion.Root} {ion.Label}'\n",
    "\n",
    "def match_as_short_str_with_tabs(m, peaks):\n",
    "    \"\"\"\n",
    "    Tab delimited mass and intensity for use elsewhere\n",
    "    \"\"\"\n",
    "    p_index, ion, mono_pk, error = m         # Unpack the peak index and the matching composition\n",
    "    p = peaks[p_index]       # peak mass and intensity\n",
    "        \n",
    "    return f'{p.Mass:.4f}\\t{p.Inten:.1f}\\t{p.RT:.2f}\\t{ion.Root}\\t{ion.Label}'\n",
    "\n",
    "def match_short_with_tabs_header():\n",
    "    \n",
    "    return \"Pk_mass\\tPk_inten\\tRT\\tRoot\\tMatch_label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_match_list(matches, peaks, print_fn, sort_order='error',simplify=False):    \n",
    "    \"\"\"\n",
    "    Use the provided print function (e.g. match_as_str) to print the matches provided\n",
    "    If simplify == True, we only print one entry and append a string to indicate there are more\n",
    "    \"\"\"\n",
    "    m_sorted = sorted(matches, key=lambda x: x.Pk_index)\n",
    "    m_grps = groupby(m_sorted, lambda x: x.Pk_index)     # group by peak index...groups with more than one entry have redundancy\n",
    "        \n",
    "    for k, grp in m_grps:\n",
    "        \n",
    "        if sort_order == 'label_len':\n",
    "            grp_as_list = sorted(list(grp), key=lambda x: len(x.TargetIon.Label))\n",
    "        elif sort_order == 'error':\n",
    "            grp_as_list = sorted(list(grp), key=lambda x: abs(x.Error))\n",
    "    \n",
    "        simplifying = simplify and (len(grp_as_list) > 1)   # do we need to simplify the output?\n",
    "\n",
    "        for g in grp_as_list:\n",
    "   \n",
    "            desc = print_fn(g, peaks)   \n",
    "                \n",
    "            if simplifying:\n",
    "                desc += f' [1/{len(grp_as_list)}]'\n",
    "            \n",
    "            print(desc)\n",
    "            \n",
    "            if simplifying: break  #only print one line\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_peak_mass_from_match(m, peaks):   \n",
    "    \"\"\"\n",
    "    Utility function to help sort peak lists...finds the mass given an index on the peak list\n",
    "    \"\"\"\n",
    "    return peaks[m.Pk_index].Mass\n",
    "\n",
    "def get_count_and_tic(grp, peaks):\n",
    "    \"\"\"\n",
    "    Given a group of matches determine the number of unique peaks and the sum of the intensity they explain\n",
    "    \"\"\"\n",
    "    \n",
    "    last_index = 0\n",
    "    count = 0\n",
    "    tic = 0\n",
    "    \n",
    "    for m in grp:\n",
    "        \n",
    "        if m.Pk_index == last_index: continue  # this is true for isotope peaks - we skip them\n",
    "        \n",
    "        last_index = m.Pk_index\n",
    "        \n",
    "        count += 1\n",
    "        tic += peaks[last_index].Inten\n",
    "        \n",
    "    return count, tic\n",
    "    \n",
    "def print_root_groups(matches, peaks, print_fn, suppress_isotopes=False, suppress_print=False):    \n",
    "    \"\"\"\n",
    "    Use the provided print function (e.g. match_as_str) to print the matches provided\n",
    "    We group the matches by the root first and sort by mass; if suppress_isotopes is True we skip\n",
    "    isotope matches (i.e. those where the Pk_index and MonoPeak are different)\n",
    "    Also returns a dictionary of group:(count, tic) that summarizes each group\n",
    "    \"\"\"\n",
    "    \n",
    "    r_sorted = sorted(matches, key=lambda x: x.TargetIon.Root)\n",
    "    r_grps = groupby(r_sorted, lambda x: x.TargetIon.Root)     # group by target root\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for k, grp in r_grps:\n",
    "        \n",
    "        # get the group as a list sorted by length of mass\n",
    "        grp_as_list = sorted(list(grp), key= lambda x: get_peak_mass_from_match(x, peaks))\n",
    "    \n",
    "        count, tic = get_count_and_tic(grp_as_list, peaks)\n",
    "        \n",
    "        if not suppress_print:\n",
    "            \n",
    "            # we can suppress isotopes by only selecting matches where the peak index and mono peak index are the same\n",
    "            if suppress_isotopes:  \n",
    "                grp_as_list = [m for m in grp_as_list if m.Pk_index == m.MonoPeak]\n",
    "            \n",
    "            for g in grp_as_list:          \n",
    "                print(print_fn(g, peaks))\n",
    "         \n",
    "            print()    # blank line after each group       \n",
    "        \n",
    "        result[k] = (count, tic)\n",
    "      \n",
    "    return result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def limits_as_string(limits):\n",
    "    \"\"\"\n",
    "    Convert a list of limits, i.e. (comp, max count) tuples, to a string\n",
    "    Skip any with max_count = 0 and join the rest with commas\n",
    "    \"\"\"\n",
    "    non_zero_limits = [l for l in limits if l[1] > 0]\n",
    "    if len(non_zero_limits) == 0:\n",
    "        return \"\"\n",
    "    else:\n",
    "        desc = \",\".join([f'{l}' for l in non_zero_limits])\n",
    "        return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comp_adduct_summary(target_conds_line):\n",
    "    \"\"\"\n",
    "    Split the target conditions line and extract the first line (a summary of the compounds and adducts)\n",
    "    \"\"\"\n",
    "    \n",
    "    parts = target_conds_line.split(';')\n",
    "    \n",
    "    return parts[0].strip()\n",
    "\n",
    "\n",
    "def print_target_conditions(ion_file, target_conds_line):\n",
    "    \"\"\"\n",
    "    Split the target conditions line and print each part on a separate line...this is read from the target file\n",
    "    \"\"\"\n",
    "    print(ion_file)\n",
    "    \n",
    "    parts = target_conds_line.split(';')\n",
    "    \n",
    "    for p in parts:\n",
    "        print(p.strip())\n",
    "        \n",
    "def write_conditions(file_path, ion_file, desc, target_conds_line=None, match_conds=None, root_res=None, tic=0):\n",
    "    \"\"\"\n",
    "    Write the conditions to the specified file.\n",
    "    This includes both target and match conditions and summary statistics for the root groups (if provided)\n",
    "    If a value is provided for the tic, the percent tic is included for each group\n",
    "    \"\"\"    \n",
    "    with open(file_path, 'w') as f:\n",
    "        \n",
    "        print(desc, file=f)\n",
    "        print(ion_file, file=f)\n",
    "    \n",
    "        if target_conds_line:\n",
    "            parts =  target_conds_line.split(';')\n",
    "    \n",
    "            for p in parts:\n",
    "                print(p.strip(), file=f)\n",
    "        \n",
    "        if match_conds:\n",
    "            for mc in match_conds:\n",
    "                print(mc, file=f)\n",
    "                \n",
    "        # Include the statistics for the root grps of specified\n",
    "        if root_res:\n",
    "            print (file=f)\n",
    "\n",
    "            for g in root_res:\n",
    "                count, int_sum = root_res[g]\n",
    "                if tic:\n",
    "                    percent_tic = int_sum * 100 / tic\n",
    "                    print(f'{g:20}\\tcount:{count:4}\\tinten sum {int_sum:12.1f}\\t% tic {percent_tic:5.1f}', file=f)\n",
    "                else:\n",
    "                    print(f'{g:20}\\tcount:{count:4}\\tinten sum {int_sum:12.1f}', file=f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rt_grouper(peaks, max_rt_gap):\n",
    "    \"\"\"\n",
    "    A simple routine to group peaks by retention time.\n",
    "    Peaks are kept together until two adjacent peaks are separated by more than 'max_rt_gap' (in minutes)\n",
    "    Note: This is not ideal since small adjacent changes may combine to make a large difference between the first and the last\n",
    "    \"\"\"\n",
    "    rt_grps = defaultdict(list)\n",
    "    rt_grp_index = 0\n",
    "    rt_last = 0\n",
    "\n",
    "    # simple group by rt routine\n",
    "    for p in sorted(peaks, key=lambda x: x.RT):\n",
    "        rt = p.RT\n",
    "        if (rt - rt_last) > max_rt_gap:\n",
    "            rt_grp_index += 1\n",
    "            \n",
    "        rt_grps[rt_grp_index] += [p]\n",
    "        \n",
    "        rt_last = rt\n",
    "    \n",
    "    return rt_grps\n",
    "\n",
    "def write_mgf(mgf_path,rt_grps, min_inten=5):\n",
    "    \"\"\"\n",
    "    A simple routine to group peaks by retention time.\n",
    "    Peaks are kept together until two adjacent peaks are separated by more than 'max_rt_gap' (in minutes)\n",
    "    Note: This is not ideal since small adjacent changes may combine to make a large difference between the first and the last\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(mgf_path,'w') as out_f:\n",
    "\n",
    "        for g in rt_grps:\n",
    "\n",
    "            int_sum = sum(p.Inten for p in rt_grps[g])\n",
    "\n",
    "            rt_min, rt_max = rt_grps[g][0].RT, rt_grps[g][0].RT\n",
    "\n",
    "            rt_str = \"RTINSECONDS={:.2f}\\n\".format(rt_min * 60.0)\n",
    "\n",
    "            title_str = f\"TITLE=RT grp {g}, rt {rt_min:.2f}-{rt_max:.2f} min., {len(rt_grps[g])} members\\n\"\n",
    "\n",
    "            out_f.write(\"BEGIN IONS\\n\")\n",
    "            out_f.write(title_str)\n",
    "            out_f.write(rt_str) \n",
    "\n",
    "            for p in sorted(rt_grps[g], key=lambda x:x.Mass):\n",
    "                m_str = f'{p.Mass:.4f}\\t{p.Inten if p.Inten > 0 else min_inten}\\n'\n",
    "                out_f.write(m_str)\n",
    "\n",
    "            out_f.write(\"END IONS\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Setup\n",
    "------------------\n",
    "\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_matches = True                # do we want to save the matched peaks (as mass, inten, match name)?\n",
    "include_large_unmatched = False    # do we want to include the larger unmatched peaks (by default > 1% base peak inten)\n",
    "include_date_in_file_name = False\n",
    "\n",
    "# the match window can be in amu or ppm (relative to mass); if both are speciefied the larger (at any mass) is used\n",
    "amu_window = 0.005     # amu half window for peak matching\n",
    "ppm_window = 10        # ppm half window for peak matching\n",
    "\n",
    "# Note: we only look for the 13C isotopes of matched peaks\n",
    "c13_half_window = 0.003     # for matching 13C isotopes\n",
    "max_C13_count = 4           # maximum number of 13C's to look for\n",
    "c13_rt_window = 0.2         # main matched peaks and isotopes must have RTs that differ by less than this\n",
    "require_lower_c13_inten = True  # if True, potential isotope peaks must have a lower intensity than the matched peak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output parameters and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_redundant_matches = True    # display matches to more than one peak \n",
    "\n",
    "write_mgfs = False               # if True, results are grouped by retention time and written as MGF files (with RT)\n",
    "max_rt_gap = 0.1                 # the maximum retention time gap\n",
    "\n",
    "save_unmatched = True            # save the unmatched ion file (saved as 'residual')\n",
    "save_matched = True              # save the matches\n",
    "\n",
    "print_unmatched = True           # print the umnmatched peaks above threshold (i.e. display in a cell)\n",
    "unmatched_print_threshold_percent = 1.0   #default threshold\n",
    "\n",
    "save_results_file = True         # save a summary of the results in a text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input files\n",
    "Here we use a directory that is shared with the calculator to facilitate interactive use (we can run the calculator notebook, switch to one this and re-run it to see the changes). \n",
    "\n",
    "The lines marked 'UPDATE!' must be changed to relect the local environment. Windows users need to specify the disk, i.e.\n",
    "\n",
    "       data_path = 'C:' + os.sep + os.path.join('Users','ronbonner','Data', 'SharedData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ronbonner/Data/SharedData/Test\n"
     ]
    }
   ],
   "source": [
    "data_path = os.sep + os.path.join('Users','ronbonner','Data', 'SharedData', 'Test')      # UPDATE!\n",
    "\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ronbonner/Data/SharedData/Test/S_4 MeOH FA pks 0.2 percent_DiMeSA_m3_5-of-Na3 residual.txt\n",
      "2896, peaks read. TIC 237581.0, base peak inten 42577.0 \n"
     ]
    }
   ],
   "source": [
    "# Read the peak file\n",
    "\n",
    "peak_file = 'S_4 MeOH FA pks 0.2 percent_DiMeSA_m3_5-of-Na3 residual.txt'\n",
    "peak_file_path = os.path.join(data_path, peak_file)\n",
    "\n",
    "peaks, tic, base_peak_mass, base_peak_inten, has_RT = read_peak_list(peak_file_path)\n",
    "\n",
    "rt_str = \"has rt\" if has_RT else \"\"\n",
    "\n",
    "print(peak_file_path)\n",
    "print(f'{len(peaks)}, peaks read. TIC {tic:.1f}, base peak inten {base_peak_inten} {rt_str}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ronbonner/Data/SharedData/Test/DiMeSA_m3_5-of-Na3Ca2 pos.txt\n",
      "72 target ions read\n",
      "DiMeSA_m3_5-of-Na3Ca2 pos.txt\n",
      "DiMeSA_m3_5-of-Na3Ca2\n",
      "Time:210705_063315\n",
      "Compounds:DiMeSA\n",
      "Multimer_limit:3\n",
      "Polarity:positive\n",
      "Adducts:('Na-H', 3),('Ca-2H', 2)\n",
      "Max adduct count:5\n",
      "Losses:('H2O', 1)\n"
     ]
    }
   ],
   "source": [
    "# Read the target ion file\n",
    "\n",
    "ion_file =  'DiMeSA_m3_5-of-Na3Ca2 pos.txt'   \n",
    "\n",
    "ion_path = os.path.join(data_path, ion_file)\n",
    "\n",
    "ions, target_conditions = read_ion_list(ion_path)\n",
    "\n",
    "compounds_as_string = get_comp_adduct_summary(target_conditions)\n",
    "\n",
    "print(ion_path)\n",
    "\n",
    "print(f'{len(ions)} target ions read')\n",
    "\n",
    "if target_conditions:\n",
    "    print_target_conditions(ion_file, target_conditions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Match ions\n",
    "\n",
    "We first match the ions generated by the calculator. In a subsequent step we look specifically for the 13C forms of matched peaks.\n",
    "\n",
    "The code allows for the possibility that any peak may match multiple targets, and any target may be matched by multple peaks. This is can occur if retention times are present (e.g. if there are isomers at different RT), if there are very close masses (e.g. from very high resolution data) or if there are many close target ions generated from complex sets of adducts, losses, heterodimers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 peaks matched (12.3% tic), 17 total matches from 2896 peaks\n"
     ]
    }
   ],
   "source": [
    "# Get the current time for use in the peak name and conditions\n",
    "current_time = datetime.datetime.now().replace(microsecond=0)\n",
    "curr_time_str = current_time.strftime('%y%m%d_%H%M%S')\n",
    "\n",
    "peak_index, ion_index, peaks_matched = 0, 0, 0\n",
    "\n",
    "matches = []   # this is going to end up as a list of Match tuples : (peak index, matched target)\n",
    "\n",
    "# Loop all the values and peaks looking for matches within the specified window\n",
    "while (ion_index < len(ions)) and (peak_index < len(peaks)):\n",
    "\n",
    "    this_peak, this_ion = peaks[peak_index], ions[ion_index]\n",
    "    low_peak, high_peak = get_mass_limits(this_peak.Mass, amu_window, ppm_window)\n",
    "    \n",
    "    # Increment the ion index if its Mass is too low and the peak if it's too high\n",
    "    if this_ion.Mass < low_peak:\n",
    "        ion_index += 1\n",
    "        continue\n",
    "\n",
    "    if this_ion.Mass > high_peak:\n",
    "        peak_index += 1\n",
    "        continue\n",
    "\n",
    "    # save peak index and ion composition\n",
    "    # since there may be more than one peak that matches this ion value, we look ahead at the peaks\n",
    "    # using a separate index so the current peak can be used with the next ion value\n",
    "    # we also track the ions matched since some ions may have more than one matching peak\n",
    "    \n",
    "    matches.append(Match(peak_index, this_ion, peak_index, this_peak.Mass - this_ion.Mass))    # reference to peak, this composition and the monopeak (this one)\n",
    "    peaks_matched += 1   \n",
    "    \n",
    "    look_ahead = peak_index + 1\n",
    " \n",
    "    # look ahead at the peaks while they're still within the search window and add any matches to the list\n",
    "    while (look_ahead < len(peaks)):\n",
    "                \n",
    "        look_ahead_peak = peaks[look_ahead]\n",
    "        \n",
    "        if(look_ahead_peak.Mass - this_ion.Mass) > get_mz_window(this_peak.Mass, amu_window, ppm_window):\n",
    "            break\n",
    "            \n",
    "        matches.append(Match(look_ahead, this_ion, look_ahead, look_ahead_peak.Mass - this_ion.Mass))\n",
    "        look_ahead +=1\n",
    "        peaks_matched += 1 \n",
    "\n",
    "\n",
    "    ion_index += 1 # increment ion index but not peak_index - there may be more than one ion within the window..\n",
    "\n",
    "matched_indices, percent_tic_matched = get_match_stats(matches, peaks, tic)\n",
    "\n",
    "matched_indices = sorted(matched_indices)\n",
    "initial_matches = f'{len(matched_indices)} peaks matched ({percent_tic_matched:.1f}% tic), {len(matches)} total matches from {len(peaks)} peaks'\n",
    "print(initial_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 peaks matched (14.1% tic), 33 total matches from 2896 peaks\n"
     ]
    }
   ],
   "source": [
    "# Look for C13 isotopes of matched peaks\n",
    "# In addition to looking for mass deltas of 1.003, we test that the retention time differences are within a specified tolerance\n",
    "# we can always apply this test since missing RTs are stored as zero so the delta is guaranteed to be less than any positive, non-zero tolerance\n",
    "# We can optionally require that the intensity of isotope peaks be less than the initial matched peak\n",
    "# We look at the peak indices since we only need to test a peak once, even if it has multiple matches\n",
    "#\n",
    "c13_matches = []\n",
    "\n",
    "last_matched_mass = 0\n",
    "last_peak_index = -1\n",
    "\n",
    "# make sure the peaks are in peak (= mass) order\n",
    "matches = sorted(matches, key=lambda x: x.Pk_index)\n",
    "\n",
    "for m in matches:    \n",
    "        \n",
    "    if m.Pk_index == last_peak_index:    #only need to look at each peak once\n",
    "        continue\n",
    "\n",
    "    peak_index = m.Pk_index    \n",
    "    last_peak_index = peak_index\n",
    "        \n",
    "    m_mass, m_inten, m_rt = peaks[peak_index]     # get the matched peak...\n",
    "        \n",
    "    next_peak_index = peak_index      #...and start looking for isotopes at the next higher peak\n",
    "        \n",
    "    keep_going = True\n",
    "    \n",
    "    for c13_count in range(1, max_C13_count+1):  #look for 1,2,3... C13\n",
    "    \n",
    "        c13_mass = m_mass + (c13_count * 1.003)   # expected c13 mass\n",
    "        c13_name = f'{m_mass:.4f}(+{c13_count})'  # name is based on mono mass with (+1) etc apended\n",
    "        \n",
    "        low_peak, high_peak = get_mass_limits(c13_mass, c13_half_window, 10)\n",
    "        \n",
    "        while next_peak_index < len(peaks) - 1:   # -1 since we're going to increment it\n",
    "            \n",
    "            next_peak_index += 1  # point at next value in peak list\n",
    "                \n",
    "            next_peak_mass, next_peak_inten, next_peak_rt = peaks[next_peak_index]\n",
    "            \n",
    "            # mass is out of range  \n",
    "            if next_peak_mass > high_peak:\n",
    "                keep_going = False       # when one isotope is not matched we abort and stop looking for more\n",
    "                break\n",
    "            \n",
    "            # if the mass is in range we also check that the RT is within a window...\n",
    "            # Note: it's OK to always apply this test since if there is no RT the values will be zero\n",
    "            # and therefore the delta will be less than the threshold\n",
    "            rt_ok = abs(m_rt-next_peak_rt) <= c13_rt_window\n",
    "            \n",
    "            if not require_lower_c13_inten:\n",
    "                inten_ok = True\n",
    "            else:\n",
    "                inten_ok = next_peak_inten < m_inten\n",
    "            \n",
    "            if next_peak_mass > low_peak and rt_ok and inten_ok:\n",
    "                c13 = Target(c13_mass, m.TargetIon.Root, c13_name)\n",
    "                c13_matches.append(Match(next_peak_index, c13, peak_index, next_peak_mass - c13_mass))\n",
    "                m_inten = next_peak_inten   #update target inten\n",
    "                break     # and look for the next higher isotope\n",
    "        \n",
    "        if not keep_going:\n",
    "            break     # leave 13c for loop   \n",
    "\n",
    "matches += c13_matches\n",
    "\n",
    "matches = sorted(matches, key = lambda x: x.Pk_index)  # sort by peak index...\n",
    "\n",
    "matched_indices, percent_tic_matched = get_match_stats(matches, peaks, tic)\n",
    "\n",
    "after_13c_match = f'{len(matched_indices)} peaks matched ({percent_tic_matched:.1f}% tic), {len(matches)} total matches from {len(peaks)} peaks'\n",
    "print(after_13c_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Print, review, save\n",
    "\n",
    "Cells illustrate various ways to report the matches:\n",
    "\n",
    "- print all or some of them inside the notebook; there is an option to show all matches, including redundant ones, or to simplify the output to only show the shortest\n",
    "- count the number of peaks that have redundant matches and optionally print them\n",
    "- print the unmatched peaks above a thershold (as percentage of the base peak intensity)\n",
    "\n",
    "Reviewing redundant peaks is useful as it can indicate that parameters need changing (if there are too many), for example: reduce the matching tolerance, reduce the number of target ions, etc.\n",
    "\n",
    "The unmatched peak list is a good way to find peaks that still need to be explained and is the basis of Multi-layered Analysis (MLA).\n",
    "\n",
    "The matched list can be written to a file for use elsewhere and a final cell summarizes the parameters and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 peaks matched (14.1% tic), 33 total matches from 2896 peaks\n",
      "  161:  166.9990 ( -2.6)   0.00        122.0   167.0016    161  DiMeSA        DiMeSA-H2O.Ca-2H.H+\n",
      "  166:  168.0035 (  1.5)   0.00         12.0   168.0020    161  DiMeSA        166.9990(+1)\n",
      "  574:  185.0100 ( -2.1)   0.00       2279.0   185.0121    574  DiMeSA        DiMeSA.Ca-2H.H+\n",
      "  583:  186.0122 ( -0.8)   0.00        129.0   186.0130    574  DiMeSA        185.0100(+1)\n",
      "  586:  187.0149 ( -1.1)   0.00         54.0   187.0160    574  DiMeSA        185.0100(+2)\n",
      "  805:  228.9807 (  4.7)   0.00         25.0   228.9760    805  DiMeSA        DiMeSA.(Na-H)2.Ca-2H.H+\n",
      "  841:  232.9515 (  4.1)   0.00        132.0   232.9474    841  DiMeSA        DiMeSA-H2O.(Na-H)3.Ca-2H.H+\n",
      " 1297:  313.0550 ( -4.5)   0.00        104.0   313.0595   1297  DiMeSA        (DiMeSA)2-H2O.Ca-2H.H+\n",
      " 1305:  314.0588 (  0.8)   0.00         19.0   314.0580   1297  DiMeSA        313.0550(+1)\n",
      " 1400:  331.0658 ( -4.2)   0.00       7150.0   331.0700   1400  DiMeSA        (DiMeSA)2.Ca-2H.H+\n",
      " 1408:  332.0693 (  0.5)   0.00        692.0   332.0688   1400  DiMeSA        331.0658(+1)\n",
      " 1414:  333.0693 ( -2.5)   0.00        141.0   333.0718   1400  DiMeSA        331.0658(+2)\n",
      " 1546:  353.0536 (  1.6)   0.00        216.0   353.0520   1546  DiMeSA        (DiMeSA)2.Na-H.Ca-2H.H+\n",
      " 1558:  354.0548 ( -1.8)   0.00         48.0   354.0566   1546  DiMeSA        353.0536(+1)\n",
      " 1643:  369.0195 (  2.5)   0.00         88.0   369.0170   1643  DiMeSA        (DiMeSA)2.(Ca-2H)2.H+\n",
      " 1659:  370.0221 ( -0.4)   0.00         16.0   370.0225   1643  DiMeSA        369.0195(+1)\n",
      " 1687:  375.0375 (  3.6)   0.00        224.0   375.0339   1687  DiMeSA        (DiMeSA)2.(Na-H)2.Ca-2H.H+\n",
      " 1693:  376.0403 ( -0.2)   0.00         40.0   376.0405   1687  DiMeSA        375.0375(+1)\n",
      " 1711:  379.0082 (  2.9)   0.00        232.0   379.0053   1711  DiMeSA        (DiMeSA)2-H2O.(Na-H)3.Ca-2H.H+\n",
      " 1720:  380.0126 (  1.4)   0.00         42.0   380.0112   1711  DiMeSA        379.0082(+1)\n",
      " 1805:  397.0192 (  3.3)   0.00         86.0   397.0159   1805  DiMeSA        (DiMeSA)2.(Na-H)3.Ca-2H.H+\n",
      " 1816:  398.0217 ( -0.5)   0.00         14.0   398.0222   1805  DiMeSA        397.0192(+1)\n",
      " 2172:  477.1232 ( -4.7)   0.00      17844.0   477.1279   2172  DiMeSA        (DiMeSA)3.Ca-2H.H+\n",
      " 2174:  478.1256 ( -0.6)   0.00       2257.0   478.1262   2172  DiMeSA        477.1232(+1)\n",
      " 2177:  479.1263 ( -2.9)   0.00        461.0   479.1292   2172  DiMeSA        477.1232(+2)\n",
      " 2186:  480.1278 ( -4.4)   0.00         91.0   480.1322   2172  DiMeSA        477.1232(+3)\n",
      " 2298:  515.0726 ( -2.3)   0.00        195.0   515.0749   2298  DiMeSA        (DiMeSA)3.(Ca-2H)2.H+\n",
      " 2300:  516.0741 ( -1.5)   0.00         52.0   516.0756   2298  DiMeSA        515.0726(+1)\n",
      " 2324:  525.0645 (  1.3)   0.00        376.0   525.0632   2324  DiMeSA        (DiMeSA)3-H2O.(Na-H)3.Ca-2H.H+\n",
      " 2327:  526.0672 ( -0.3)   0.00         86.0   526.0675   2324  DiMeSA        525.0645(+1)\n",
      " 2350:  537.0569 (  0.1)   0.00        103.0   537.0568   2350  DiMeSA        (DiMeSA)3.Na-H.(Ca-2H)2.H+\n",
      " 2396:  559.0384 ( -0.4)   0.00         35.0   559.0388   2396  DiMeSA        (DiMeSA)3.(Na-H)2.(Ca-2H)2.H+\n",
      " 2432:  581.0204 ( -0.3)   0.00         22.0   581.0207   2432  DiMeSA        (DiMeSA)3.(Na-H)3.(Ca-2H)2.H+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the matches for review. To print a few matches use, for example, matches[:40]\n",
    "# There may be redundant matches (i.e. more than one match for a peak)  so, if 'simplify' is True, only the first label is printed\n",
    "# with a notation indicating that there are others. The first is determined by the sort order which can be 'error' of 'label_len'..\n",
    "# the idea of the latter is that the shortest label is aslso the simplest\n",
    "\n",
    "print(after_13c_match)\n",
    "print_match_list(matches[:40], peaks, match_as_str, sort_order='error', simplify=False)  # remove '40' to see all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  161:  166.9990 ( -2.6)   0.00        122.0   167.0016    161  DiMeSA        DiMeSA-H2O.Ca-2H.H+\n",
      "  166:  168.0035 (  1.5)   0.00         12.0   168.0020    161  DiMeSA        166.9990(+1)\n",
      "  574:  185.0100 ( -2.1)   0.00       2279.0   185.0121    574  DiMeSA        DiMeSA.Ca-2H.H+\n",
      "  583:  186.0122 ( -0.8)   0.00        129.0   186.0130    574  DiMeSA        185.0100(+1)\n",
      "  586:  187.0149 ( -1.1)   0.00         54.0   187.0160    574  DiMeSA        185.0100(+2)\n",
      "  805:  228.9807 (  4.7)   0.00         25.0   228.9760    805  DiMeSA        DiMeSA.(Na-H)2.Ca-2H.H+\n",
      "  841:  232.9515 (  4.1)   0.00        132.0   232.9474    841  DiMeSA        DiMeSA-H2O.(Na-H)3.Ca-2H.H+\n",
      " 1297:  313.0550 ( -4.5)   0.00        104.0   313.0595   1297  DiMeSA        (DiMeSA)2-H2O.Ca-2H.H+\n",
      " 1305:  314.0588 (  0.8)   0.00         19.0   314.0580   1297  DiMeSA        313.0550(+1)\n",
      " 1400:  331.0658 ( -4.2)   0.00       7150.0   331.0700   1400  DiMeSA        (DiMeSA)2.Ca-2H.H+\n",
      " 1408:  332.0693 (  0.5)   0.00        692.0   332.0688   1400  DiMeSA        331.0658(+1)\n",
      " 1414:  333.0693 ( -2.5)   0.00        141.0   333.0718   1400  DiMeSA        331.0658(+2)\n",
      " 1546:  353.0536 (  1.6)   0.00        216.0   353.0520   1546  DiMeSA        (DiMeSA)2.Na-H.Ca-2H.H+\n",
      " 1558:  354.0548 ( -1.8)   0.00         48.0   354.0566   1546  DiMeSA        353.0536(+1)\n",
      " 1643:  369.0195 (  2.5)   0.00         88.0   369.0170   1643  DiMeSA        (DiMeSA)2.(Ca-2H)2.H+\n",
      " 1659:  370.0221 ( -0.4)   0.00         16.0   370.0225   1643  DiMeSA        369.0195(+1)\n",
      " 1687:  375.0375 (  3.6)   0.00        224.0   375.0339   1687  DiMeSA        (DiMeSA)2.(Na-H)2.Ca-2H.H+\n",
      " 1693:  376.0403 ( -0.2)   0.00         40.0   376.0405   1687  DiMeSA        375.0375(+1)\n",
      " 1711:  379.0082 (  2.9)   0.00        232.0   379.0053   1711  DiMeSA        (DiMeSA)2-H2O.(Na-H)3.Ca-2H.H+\n",
      " 1720:  380.0126 (  1.4)   0.00         42.0   380.0112   1711  DiMeSA        379.0082(+1)\n",
      " 1805:  397.0192 (  3.3)   0.00         86.0   397.0159   1805  DiMeSA        (DiMeSA)2.(Na-H)3.Ca-2H.H+\n",
      " 1816:  398.0217 ( -0.5)   0.00         14.0   398.0222   1805  DiMeSA        397.0192(+1)\n",
      " 2172:  477.1232 ( -4.7)   0.00      17844.0   477.1279   2172  DiMeSA        (DiMeSA)3.Ca-2H.H+\n",
      " 2174:  478.1256 ( -0.6)   0.00       2257.0   478.1262   2172  DiMeSA        477.1232(+1)\n",
      " 2177:  479.1263 ( -2.9)   0.00        461.0   479.1292   2172  DiMeSA        477.1232(+2)\n",
      " 2186:  480.1278 ( -4.4)   0.00         91.0   480.1322   2172  DiMeSA        477.1232(+3)\n",
      " 2298:  515.0726 ( -2.3)   0.00        195.0   515.0749   2298  DiMeSA        (DiMeSA)3.(Ca-2H)2.H+\n",
      " 2300:  516.0741 ( -1.5)   0.00         52.0   516.0756   2298  DiMeSA        515.0726(+1)\n",
      " 2324:  525.0645 (  1.3)   0.00        376.0   525.0632   2324  DiMeSA        (DiMeSA)3-H2O.(Na-H)3.Ca-2H.H+\n",
      " 2327:  526.0672 ( -0.3)   0.00         86.0   526.0675   2324  DiMeSA        525.0645(+1)\n",
      " 2350:  537.0569 (  0.1)   0.00        103.0   537.0568   2350  DiMeSA        (DiMeSA)3.Na-H.(Ca-2H)2.H+\n",
      " 2396:  559.0384 ( -0.4)   0.00         35.0   559.0388   2396  DiMeSA        (DiMeSA)3.(Na-H)2.(Ca-2H)2.H+\n",
      " 2432:  581.0204 ( -0.3)   0.00         22.0   581.0207   2432  DiMeSA        (DiMeSA)3.(Na-H)3.(Ca-2H)2.H+\n",
      "\n",
      "DiMeSA      \tcount:  33\tinten sum      33387.0,  14.1% tic\n"
     ]
    }
   ],
   "source": [
    "# We can also organize the matches by root before printing..\n",
    "# The matches are sorted in peak (mass) order and isotopes can be skipped by setting suppress_isotopes = True\n",
    "# print_root_groups returns a dictionary which summarizes the results for each root group\n",
    "#\n",
    "# i.e. number of members, intensity and percent tic...\n",
    "# if suppress_print is true the peaks are not printed and only the summary dictionary is returned\n",
    "\n",
    "grp_stats = print_root_groups(matches, peaks, match_as_str, suppress_isotopes = False, suppress_print=False)\n",
    "\n",
    "for g in grp_stats:\n",
    "    count, int_sum = grp_stats[g]\n",
    "    percent_tic = int_sum * 100 / tic\n",
    "    print(f'{g:12}\\tcount:{count:4}\\tinten sum {int_sum:12.1f}, {percent_tic:5.1f}% tic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  redundant peaks have 0 matches\n"
     ]
    }
   ],
   "source": [
    "# It can be useful to review the redundant matches, i.e. peaks that have multiple matches, since these can indicate adduct/loss/modifcation combinations\n",
    "# that result in the same mass suggesting opprotunities to simplify the lists\n",
    "\n",
    "if show_redundant_matches:\n",
    "    \n",
    "    redundant_peak_count, redundant_matches = get_redundant_matches(matches)\n",
    "\n",
    "    print(redundant_peak_count,' redundant peaks have', len(redundant_matches), 'matches')\n",
    "\n",
    "    print_redundant_matches = True\n",
    "\n",
    "    # To make the list easier to read, we add a blank line between the redundant groups\n",
    "    if print_redundant_matches:\n",
    "\n",
    "        last_index = -1\n",
    "        for m in redundant_matches:\n",
    "            if m.Pk_index != last_index:   # when the Pk_index changes...\n",
    "                print()\n",
    "                last_index = m.Pk_index\n",
    "\n",
    "            print(match_as_str(m, peaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is useful to print the largest unmatched peaks since these suggest opportunities to modify the Calculator parameters\n",
    "# to get greater coverage. Some peaks may be easy to explain (unusual isotopes, obvious losses, etc.)\n",
    "# Unexplained, large peaks can be included in the Calculator, for example,  ('x544', 544.2148)\n",
    "#\n",
    "# get the unmatched indices and peaks \n",
    "\n",
    "unmatched_indices = get_unmatched_indices(matched_indices, peaks)  # get the unmatched peaks; default threshold = 0\n",
    "\n",
    "unmatched_peaks = [peaks[pi] for pi in unmatched_indices]\n",
    "\n",
    "#get the matched peaks\n",
    "matched_peaks = []\n",
    "\n",
    "for m in matches:\n",
    "    p = peaks[m.Pk_index]\n",
    "    t = m.TargetIon\n",
    "    mp = MatchedPeak(p.Mass, p.RT, p.Inten, t.Mass, t.Label,m.MonoPeak, Error=m.Error)\n",
    "    matched_peaks.append(mp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If the output MGF files are required we first group the peaks by RT\n",
    "if write_mgfs:\n",
    "    \n",
    "    matched_grps = rt_grouper(matched_peaks, max_rt_gap)\n",
    "    \n",
    "    mgf_dir, _ = os.path.splitext(peak_file_path)    # path without extension\n",
    "\n",
    "    mgf_path = f'{mgf_dir}_{compounds_as_string} matched.mgf'       \n",
    "\n",
    "    write_mgf(mgf_path, matched_grps)\n",
    "\n",
    "    print (\"Finished matched\", len(matched_grps), 'groups',  mgf_path)\n",
    "    \n",
    "    unmatched_grps = rt_grouper(unmatched_peaks, max_rt_gap)\n",
    "\n",
    "    mgf_path = f'{mgf_dir}_{compounds_as_string} residual.mgf'       \n",
    "\n",
    "    write_mgf(mgf_path, unmatched_grps)\n",
    "\n",
    "    print (\"Finished unmatched\", len(unmatched_grps), 'groups', mgf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100.0736     0.00       3526     8.28% base peak\n",
      "  101.0576     0.00       1022     2.40% base peak\n",
      "  114.0891     0.00        486     1.14% base peak\n",
      "  154.9040     0.00        547     1.28% base peak\n",
      "  161.0930     0.00        562     1.32% base peak\n",
      "  182.8992     0.00        884     2.08% base peak\n",
      "  189.0308     0.00        454     1.07% base peak\n",
      "  206.9997     0.00        448     1.05% base peak\n",
      "  215.0067     0.00        662     1.55% base peak\n",
      "  217.0254     0.00        683     1.60% base peak\n",
      "  239.0638     0.00        491     1.15% base peak\n",
      "  257.2442     0.00        451     1.06% base peak\n",
      "  277.0561     0.00        565     1.33% base peak\n",
      "  277.1762     0.00       1783     4.19% base peak\n",
      "  282.9513     0.00       2019     4.74% base peak\n",
      "  288.0344     0.00       1817     4.27% base peak\n",
      "  299.1583     0.00        458     1.08% base peak\n",
      "  301.1371     0.00       1566     3.68% base peak\n",
      "  317.0776     0.00       3304     7.76% base peak\n",
      "  317.1676     0.00       1622     3.81% base peak\n",
      "  335.0869     0.00       1384     3.25% base peak\n",
      "  346.0302     0.00        599     1.41% base peak\n",
      "  347.0373     0.00        926     2.17% base peak\n",
      "  349.1027     0.00       1910     4.49% base peak\n",
      "  371.0964     0.00       1099     2.58% base peak\n",
      "  371.3105     0.00       1264     2.97% base peak\n",
      "  381.0462     0.00        615     1.44% base peak\n",
      "  393.2920     0.00        565     1.33% base peak\n",
      "  409.1238     0.00        457     1.07% base peak\n",
      "  423.1120     0.00        939     2.21% base peak\n",
      "  428.0079     0.00        500     1.17% base peak\n",
      "  429.0079     0.00       3812     8.95% base peak\n",
      "  449.1179     0.00        589     1.38% base peak\n",
      "  461.1444     0.00        487     1.14% base peak\n",
      "  463.1343     0.00      42577   100.00% base peak\n",
      "  464.1380     0.00       5757    13.52% base peak\n",
      "  483.1387     0.00        822     1.93% base peak\n",
      "  485.1150     0.00       1270     2.98% base peak\n",
      "  492.0869     0.00       5645    13.26% base peak\n",
      "  493.0921     0.00       2469     5.80% base peak\n",
      "  494.0946     0.00        427     1.00% base peak\n",
      "  499.1028     0.00        859     2.02% base peak\n",
      "  505.1194     0.00        632     1.48% base peak\n",
      "  507.0971     0.00        677     1.59% base peak\n",
      "  574.0650     0.00        467     1.10% base peak\n",
      "  575.0639     0.00       3936     9.24% base peak\n",
      "  576.0665     0.00        530     1.24% base peak\n",
      "  623.1786     0.00       1507     3.54% base peak\n",
      "48 peaks >= 1.0%\n",
      "2863 unmatched Largest unmatched 463.1343, 42577.0 100.0% base\n"
     ]
    }
   ],
   "source": [
    "# find the larget unmtached peak an optionally print the unmatched peaks above threshold\n",
    "bpi_percent_thresh = unmatched_print_threshold_percent * base_peak_inten / 100   # convert to counts\n",
    "\n",
    "unmatched_mass, largest_unmatched_inten, print_count = 0, 0, 0\n",
    "\n",
    "for pi in unmatched_peaks:\n",
    "\n",
    "    if print_unmatched and (pi.Inten > bpi_percent_thresh):\n",
    "        percent_base_peak = pi.Inten * 100/ base_peak_inten\n",
    "        print(f'{pi.Mass:10.4f} {pi.RT:8.2f} {pi.Inten:10.0f} {percent_base_peak:8.2f}% base peak')\n",
    "        print_count += 1\n",
    "    \n",
    "    if pi.Inten >= largest_unmatched_inten:\n",
    "        unmatched_mass, largest_unmatched_inten = pi.Mass,pi.Inten\n",
    "\n",
    "print(f'{print_count} peaks >= {unmatched_print_threshold_percent:.1f}%')\n",
    "large_inten_rel = largest_unmatched_inten * 100/ base_peak_inten\n",
    "\n",
    "largest_unmatched_string = f'Largest unmatched {unmatched_mass}, {largest_unmatched_inten} {large_inten_rel:.1f}% base'\n",
    "\n",
    "print(len(unmatched_indices), 'unmatched', largest_unmatched_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Match time: 210705_071156', 'Peaks file: /Users/ronbonner/Data/SharedData/Test/S_4 MeOH FA pks 0.2 percent_DiMeSA_m3_5-of-Na3 residual.txt', '2896 peaks, tic 237581.0, base peak 463.13430, inten 42577.0', 'Matching amu half window: 0.005', 'Matching ppm half window: 10 ppm', 'Looking for <= 4 13C isotopes with half window 0.003', '17 peaks matched (12.3% tic), 17 total matches from 2896 peaks', 'After 13C match 33 peaks matched (14.1% tic), 33 total matches from 2896 peaks', '2863 unmatched peaks gt 1.0%, Largest unmatched 463.1343, 42577.0 100.0% base']\n"
     ]
    }
   ],
   "source": [
    "# We make a list of strings containing the match conditions so they can be saved to the ouput files\n",
    "# and printed (below)\n",
    "match_conditions = [f'Match time: {curr_time_str}']\n",
    "match_conditions.append(f'Peaks file: {peak_file_path}')\n",
    "match_conditions.append(f'{len(peaks)} peaks, tic {tic:.1f}, base peak {base_peak_mass:.5f}, inten {base_peak_inten:.1f}')\n",
    "match_conditions.append(f'Matching amu half window: {amu_window}')\n",
    "match_conditions.append(f'Matching ppm half window: {ppm_window} ppm')\n",
    "\n",
    "match_conditions.append(f'Looking for <= {max_C13_count} 13C isotopes with half window {c13_half_window}')\n",
    "\n",
    "match_conditions.append(initial_matches)\n",
    "match_conditions.append(f'After 13C match {after_13c_match}')\n",
    "\n",
    "match_conditions.append(f'{len(unmatched_indices)} unmatched peaks gt {unmatched_print_threshold_percent}%, {largest_unmatched_string}')\n",
    "\n",
    "print(match_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ronbonner/Data/SharedData/Test/S_4 MeOH FA pks 0.2 percent_DiMeSA_m3_5-of-Na3_DiMeSA_m3_5-of-Na3Ca2 matches.txt ; 33  lines\n",
      "/Users/ronbonner/Data/SharedData/Test/S_4 MeOH FA pks 0.2 percent_DiMeSA_m3_5-of-Na3_DiMeSA_m3_5-of-Na3Ca2 residual.txt ; 2863 lines\n",
      "/Users/ronbonner/Data/SharedData/Test/S_4 MeOH FA pks 0.2 percent_DiMeSA_m3_5-of-Na3_DiMeSA_m3_5-of-Na3Ca2 summary.txt ; summary file\n"
     ]
    }
   ],
   "source": [
    "# simple summary line\n",
    "desc = f'{current_time}, {len(ions)} targets'\n",
    "\n",
    "# make one output path for all save operations\n",
    "# If the peak file name ends in 'residual' we remove it before adding the compound/adduct summary string\n",
    "# The assumption is that this is part of an MLA analysis\n",
    "out_path, _ = os.path.splitext(peak_file_path)    # path without extension\n",
    "\n",
    "out_path = re.sub(' residual$', '', out_path)   # remove ' residual' if it's at the end of the file path\n",
    "\n",
    "out_path += f'_{compounds_as_string}'\n",
    "\n",
    "date_time_str = \" \" + curr_time_str if include_date_in_file_name else \"\"  \n",
    "\n",
    "# Save the match list if needed\n",
    "if save_matches:\n",
    "    \n",
    "    save_path = \"\".join([out_path, ' matches', date_time_str, \".txt\"])\n",
    "    \n",
    "    to_save = matches\n",
    "    \n",
    "    to_save = sorted(to_save, key = lambda x: x[0])\n",
    "\n",
    "    lines_written_count = save_matches_to_file(save_path, to_save, peaks, target_conditions, match_conditions, with_details=True)\n",
    "    \n",
    "    print(save_path,';', lines_written_count, ' lines')    \n",
    "\n",
    "# save the unmatched as residual\n",
    "if save_unmatched:\n",
    "\n",
    "    save_path = \"\".join([out_path, ' residual', date_time_str, \".txt\"])\n",
    "    \n",
    "    to_save = matches\n",
    "    \n",
    "    with open(save_path,'w') as f:\n",
    "        for pi in unmatched_peaks:\n",
    "            print(f'{pi.Mass:.4f}\\t{pi.Inten:.0f}', file=f)\n",
    "    \n",
    "    print(save_path, ';', len(unmatched_peaks), 'lines')\n",
    "\n",
    "if save_results_file:\n",
    "    \n",
    "    save_path = \"\".join([out_path, ' summary', date_time_str, \".txt\"])\n",
    "  \n",
    "    write_conditions(save_path, ion_file, desc, target_conds_line=target_conditions, match_conds=match_conditions,\\\n",
    "                 root_res=grp_stats, tic=tic)\n",
    "    \n",
    "    print(save_path, '; summary file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-05 07:11:56, 72 targets\n",
      "DiMeSA_m3_5-of-Na3Ca2 pos.txt\n",
      "DiMeSA_m3_5-of-Na3Ca2\n",
      "Time:210705_063315\n",
      "Compounds:DiMeSA\n",
      "Multimer_limit:3\n",
      "Polarity:positive\n",
      "Adducts:('Na-H', 3),('Ca-2H', 2)\n",
      "Max adduct count:5\n",
      "Losses:('H2O', 1)\n",
      "\n",
      "Match time: 210705_071156\n",
      "Peaks file: /Users/ronbonner/Data/SharedData/Test/S_4 MeOH FA pks 0.2 percent_DiMeSA_m3_5-of-Na3 residual.txt\n",
      "2896 peaks, tic 237581.0, base peak 463.13430, inten 42577.0\n",
      "Matching amu half window: 0.005\n",
      "Matching ppm half window: 10 ppm\n",
      "Looking for <= 4 13C isotopes with half window 0.003\n",
      "17 peaks matched (12.3% tic), 17 total matches from 2896 peaks\n",
      "After 13C match 33 peaks matched (14.1% tic), 33 total matches from 2896 peaks\n",
      "2863 unmatched peaks gt 1.0%, Largest unmatched 463.1343, 42577.0 100.0% base\n"
     ]
    }
   ],
   "source": [
    "# Finally we summarize the results here\n",
    "\n",
    "print (desc)\n",
    "\n",
    "if target_conditions:\n",
    "    print_target_conditions(ion_file, target_conditions)\n",
    "\n",
    "print()\n",
    "for mc in match_conditions:\n",
    "    print (mc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
