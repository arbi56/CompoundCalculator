{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching 20201105\n",
    "\n",
    "Compares a list of masses and labels generated with CompoundCalculator to an input peak list. It is convenient to open the Calculator and Match notebooks in side-by-side windows (Jupyter Lab allows this) so it is easy to update the target ion list and repeat the matching.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The program matches the target ion and peak lists using a tolerance that can be specified in amu (fixed( or ppm (increases with mass). If both are non-zero the ppm is calulated and the larger window used which allows the window to increase with mass but never be less that a certain value. The program also allows for the possibility that complex peak and target ion lists can result in multiple matches for each peak. The function that prints the matches has a simplify mode which shows only one match for each peak but appends a string showing the number of matches; the match shown is the one with the smallest absolute error. Matched peaks can be grouped according to the 'root' field, which is part of the target ion list, and there is a cell that shows peaks with redundant matches to emphasize their existence and allow adjustment of the matching or ion generation parameters if necessary.\n",
    "\n",
    "Unmatched peaks greater than a given intensity threshold (percent base peak intensity) are also displayed. The idea is that this is part of interactive spectrum interpretation, i.e. once the origin of unmatched peaks is understood the ion generation parameters can be adjusted and applied to other peaks.\n",
    "\n",
    "In order to ensure that isotope peaks stay with the monoisotopic peaks, the program only searches for 13C peaks for matched peaks. Identified isotope peaks are Peaks identified as isotopes can also match entries in the target ion list so other possibilities are shown. In the output lists each peak has an index as well as the index of a related monoisotopic peak; these are the same for actual monoisotopic peaks.\n",
    "\n",
    "The peak list must be tab-delimited and have mass values but can also contain columns for Retention Time (RT) and Intensity; the function that reads the peak list tries to determine which columns are present.\n",
    "\n",
    "Results can be saved in several ways including a simple mass/intensity list and more detailed lists. Text lists can be imported into PeakView as spectra and overlaid on the original data to visualize the matches and highlight unmatched peaks.\n",
    "\n",
    "## Imports and function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime \n",
    "from collections import namedtuple\n",
    "from itertools import groupby\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some named tuples to hold the data and results\n",
    "Peak = namedtuple('Peak', 'Mass Inten RT')\n",
    "Target = namedtuple('Target', 'Mass Root Label')\n",
    "\n",
    "# a match contains the index of the peak, the calculated ion it matches, the index of the monoisotopic peak (if applicable) and the mass error\n",
    "# the latter fields allow the matched lists to be redily sorted and filtered\n",
    "Match = namedtuple('Match', 'Pk_index TargetIon MonoPeak Error')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_from_line(line):\n",
    "    \"\"\"\n",
    "    Split a line into parts and try to convert them to numbers...return the list of numbers or fields\n",
    "    \"\"\"\n",
    "    \n",
    "    parts = line.split()\n",
    "    \n",
    "    try:\n",
    "        vals = [float(field) for field in parts]  # convert all to numbers\n",
    "        success = True\n",
    "    except:\n",
    "        vals = parts      # return the fields if the conversion fails\n",
    "        success = False\n",
    "    \n",
    "    return success, vals\n",
    "    \n",
    "    \n",
    "def read_peak_list(peak_file_path):\n",
    "    \"\"\"\n",
    "    Reads a tab-delimited text file generating a list of Peak tuples (Mass, Inten, RT). Mass must be present but the other fields are optional\n",
    "    and will be stored internally as zero if absent.\n",
    "    If the file has only one column it is assumed to contain masses otherwise the code assumes that the first column is Mass,\n",
    "    the second is Inten and the RT is absent.\n",
    "    If the file contains a header line it is used to define the order of the columns by looking for matches with common labels\n",
    "    e.g. mz, m/z, Mass, etc. for masses. The RT column can only be used via a header line containi 'RT' or 'rt'\n",
    "    \"\"\"\n",
    "    mass_col = 0\n",
    "    inten_col = 1\n",
    "    rt_col = -1\n",
    "    has_rt = False\n",
    "    has_inten = True\n",
    "    start_line= 0\n",
    "    \n",
    "    peaks = []    #list of (mass, inten, RT) tuples\n",
    "\n",
    "    # read all the lines so we can process them one-by-one\n",
    "    with open(peak_file_path, 'r') as f:  \n",
    "    \n",
    "        lines = f.readlines()\n",
    "        \n",
    "        f.close()\n",
    "    \n",
    "    success, vals = values_from_line(lines[0])  # try to convert the first line\n",
    "    \n",
    "    if not success:   # couldn't get values; probably a header....vals is a list of the parts\n",
    "\n",
    "        # see if we can figure out what the columns are...lsist can be extende if needed\n",
    "        for col_index, col in enumerate(vals):\n",
    "            if col in ['mz', 'm/z', 'mass', 'Mass', 'Mass/Charge']: mass_col = col_index\n",
    "            if col in ['Int', 'Inten', 'inten', 'Height']: inten_col = col_index\n",
    "            if col in ['RT', 'rt']: rt_col = col_index\n",
    "\n",
    "        has_rt = rt_col > -1\n",
    "        has_inten = inten_col > -1\n",
    "            \n",
    "        start_line = 1     # can skip this line\n",
    "\n",
    "        print('m:', mass_col, 'Int:', inten_col, 'RT:', rt_col)\n",
    "        \n",
    "    base_peak_mass, base_peak_inten = 0,0\n",
    "\n",
    "    # Process line by line. Lines that cannot be converted to numbers are reported \n",
    "    # Note: the first line will be reprocessed if it is numeric\n",
    "    for line in lines[start_line:]:        \n",
    "\n",
    "        # get a list of numbers from the fields in the line - success will be false if this fails and vals will be the actual text parts\n",
    "        success, vals = values_from_line(line)  \n",
    "               \n",
    "        if success:\n",
    "            mass = vals[mass_col]\n",
    "            rt = vals[rt_col] if has_rt else 0\n",
    "            inten = vals[inten_col] if has_inten else 0\n",
    "            \n",
    "            p = Peak(mass, inten, rt)\n",
    "              \n",
    "            peaks.append(p)\n",
    "            \n",
    "            if inten > base_peak_inten:\n",
    "                base_peak_inten = inten\n",
    "                base_peak_mass = mass\n",
    "            \n",
    "        else:\n",
    "            print('Problem in line:', line, vals)   # vals will be the list of fields if there's a problem\n",
    "    \n",
    "    peaks = sorted(peaks, key = lambda x: x.Mass)     # ensure the list is sorted by mass\n",
    "\n",
    "    masses, intens, rts = zip(*peaks)\n",
    "\n",
    "    # Note: intensity params will be 0 if there is no intensity column\n",
    "    return peaks, sum(intens), base_peak_mass, base_peak_inten, has_rt    # peaks, tic, base_peak_inten, sum rts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ion_list(ion_file_path):\n",
    "    \"\"\"\n",
    "    Read the taget ion file which is assumed to contain fields for mass, root and label that can be convertes to a Target\n",
    "    \"\"\"\n",
    "    \n",
    "    ions = []            #list of (mass, root, label) tuples\n",
    "    cond_str = \"\"        # conditions line if ptrsdrnt\n",
    "    \n",
    "    with open(ion_file_path, 'r') as f:  \n",
    "    \n",
    "        for line in f:\n",
    "            \n",
    "            if line[0] == '#':             # if the first character is '#' this is a condition line\n",
    "                cond_str = line[1:]\n",
    "                continue\n",
    "            \n",
    "            parts = line.split()\n",
    "            \n",
    "            try:\n",
    "                ion = Target(float(parts[0]), parts[1], parts[2])\n",
    "                ions.append(ion) \n",
    "            except:\n",
    "                print('Problem in', line)\n",
    "\n",
    "        f.close()\n",
    "    \n",
    "    ions = sorted(ions, key = lambda x: x.Mass)     # ensure the list is sorted by mass\n",
    "\n",
    "    return ions, cond_str    # target ions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mz_window(mz, amu, ppm):\n",
    "    \"\"\"\n",
    "    Determine the mass window to use for matching either as ppm or amu.\n",
    "    If both are supplied the larger will be used; this allows the window to increase with mass (ppm) but\n",
    "    never be smaller than amu.\n",
    "    If either is zero, the other is automatically used    \n",
    "    \"\"\"\n",
    "    ppm_window = mz * ppm /1e6\n",
    "    \n",
    "    if ppm_window > amu:\n",
    "        return ppm_window\n",
    "    else:\n",
    "        return amu\n",
    "    \n",
    "def get_mass_limits(mz, amu, ppm):\n",
    "    \"\"\"\n",
    "    Uses get_mz_window to determine the window size and returns the upper an lower mass limits\n",
    "    \"\"\"\n",
    "    window = get_mz_window(mz, amu, ppm)\n",
    "    return mz - window, mz + window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_stats(matches, peaks, tic):\n",
    "    \"\"\"\n",
    "    Given lists of peaks and matches, returns the indices of the matched peaks and the percentage\n",
    "    of the TIC that they explain\n",
    "    \"\"\"\n",
    "\n",
    "    matched_indices = set([m.Pk_index for m in matches])   # get the peak indices; we uae a set so each peak occurs only once\n",
    "\n",
    "    matched_inten = sum([peaks[i].Inten for i in matched_indices])  # sum the intensities\n",
    "\n",
    "    percent_matched = matched_inten * 100/tic\n",
    "    \n",
    "    return matched_indices, percent_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redundant_matches(matches):\n",
    "    \"\"\"\n",
    "    Find which peaks have multiple matches.\n",
    "    We group the matches by peak index and then find which groups have more than one entry\n",
    "    We return the count and the redundant groups individually sorted by absolute error\n",
    "    \"\"\"\n",
    "    redundant = []\n",
    "    redundant_peak_count = 0   # Number of peaks with more than one match\n",
    "    \n",
    "    m_sorted = sorted(matches, key=lambda x: x.Pk_index)\n",
    "    m_grps = groupby(m_sorted, lambda x: x.Pk_index)\n",
    "    \n",
    "    for k, grp in m_grps:\n",
    "        \n",
    "        # to get the group as a list sorted by the length of the label use the following\n",
    "#       grp_as_list = sorted(list(grp), key= lambda x: len(x[1].Label))\n",
    "        \n",
    "        # get the group as a list sorted by absolute error\n",
    "        grp_as_list = sorted(list(grp), key= lambda x: abs(x.Error))\n",
    "\n",
    "        if len(grp_as_list) > 1:\n",
    "            redundant += grp_as_list\n",
    "            redundant_peak_count += 1\n",
    "        \n",
    "    return redundant_peak_count, redundant\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unmatched_indices(matched_indices, peaks, threshold):\n",
    "    \"\"\"\n",
    "    Find the indices of unmatched peaks that exceed a threshold\n",
    "    \"\"\"    \n",
    "    # get a boolean list indicating which peak is matched\n",
    "    peak_matches = [True if i in matched_indices else False for i in range(len(peaks))]\n",
    "    \n",
    "    # now find which ones ae false\n",
    "    unmatched = [i for i in range(len(peaks)) if not peak_matches[i]]\n",
    "    \n",
    "    return [i for i in unmatched if peaks[i].Inten >= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_matches_to_file(out_path, matches_to_save, peaks, conditions, match_conditions, with_details=False):\n",
    "    \"\"\"\n",
    "    Save the list of matches to a file. We use one of the print functions to do this\n",
    "    \"\"\"\n",
    "    with open(out_path, 'w') as f: \n",
    "        \n",
    "        # combine the conditions and match conditions in a single string\n",
    "        match_conds_str = ';'.join(match_conditions)\n",
    "        \n",
    "        if conditions:\n",
    "            conds =  ';'.join([conditions.rstrip(), match_conds_str])\n",
    "        else:\n",
    "            conds = match_conds_str\n",
    "\n",
    "        print(conds, file=f)\n",
    "            \n",
    "        if with_details:\n",
    "            print(match_with_tabs_header(), file=f)\n",
    "            for m in matches_to_save:         \n",
    "                print(match_as_str_with_tabs(m, peaks), file=f)\n",
    "        else:\n",
    "            print(match_short_with_tabs_header(), file=f)\n",
    "            for m in matches_to_save: \n",
    "                print(match_as_short_str_with_tabs(m, peaks), file=f)\n",
    "                \n",
    "        f.close()\n",
    "\n",
    "    return(len(to_save))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that convert a match to various output strings\n",
    "def match_as_str(m, peaks):\n",
    "    \"\"\"\n",
    "    Prettified string for printing in a Notebook cell\n",
    "    \"\"\"    \n",
    "    p_index, ion, mono_pk, error = m         # Unpack the peak index and the matching composition\n",
    "    p = peaks[p_index]       # peak mass and intensity\n",
    "    \n",
    "    error = error * 1000   # error in mmu   \n",
    "    \n",
    "    return f'{p_index:5}:{p.Mass:10.4f} ({error:5.1f}) {p.RT:6.2f} {p.Inten:12.1f} {ion.Mass:10.4f} {mono_pk:6}  {ion.Root:14}{ion.Label}'\n",
    "\n",
    "def match_as_str_with_tabs(m, peaks):\n",
    "    \"\"\"\n",
    "   Tab delimited detailed string.\n",
    "    \"\"\"    \n",
    "    p_index, ion, mono_pk, error   = m       # Unpack the peak index and the matching composition\n",
    "    p = peaks[p_index]       # peak mass and intensity\n",
    "    \n",
    "    error = error * 1000   # error in mmu   \n",
    "        \n",
    "    return f'{p.Mass:.4f}\\t{p.Inten:.1f}\\t{error:.1f}\\t{p.RT:.1f}\\t{p_index}\\t{mono_pk}\\t{ion.Mass:.4f}\\t{ion.Root:12}\\t{ion.Label}' \n",
    "\n",
    "def match_with_tabs_header():\n",
    "    \n",
    "    return \"Pk_mass\\tPk_inten\\tDelta_mmu\\tPk_RT\\tPk_index\\tMono__pk\\tMatch_mass\\tMatch_root\\tMatch_label\"\n",
    "\n",
    "def match_as_short_str(m, peaks):\n",
    "    \"\"\"\n",
    "    Simplified pretty string\n",
    "    \"\"\"\n",
    "    p_index, ion, mono_pk, error = m         # Unpack the peak index and the matching composition\n",
    "    p = peaks[p_index]       # peak mass and intensity\n",
    "        \n",
    "    return f'{p.Mass:10.4f} {p.Inten:12.1f} {p.RT:6.2f} {ion.Root} {ion.Label}'\n",
    "\n",
    "def match_as_short_str_with_tabs(m, peaks):\n",
    "    \"\"\"\n",
    "    Tab delimited mass and intensity for use elsewhere\n",
    "    \"\"\"\n",
    "    p_index, ion, mono_pk, error = m         # Unpack the peak index and the matching composition\n",
    "    p = peaks[p_index]       # peak mass and intensity\n",
    "        \n",
    "    return f'{p.Mass:.4f}\\t{p.Inten:.1f}\\t{p.RT:.2f}\\t{ion.Root}\\t{ion.Label}'\n",
    "\n",
    "def match_short_with_tabs_header():\n",
    "    \n",
    "    return \"Pk_mass\\tPk_inten\\tRT\\tRoot\\tMatch_label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_match_list(matches, peaks, print_fn, sort_order='error',simplify=False):    \n",
    "    \"\"\"\n",
    "    Use the provided print function (e.g. match_as_str) to print the matches provided\n",
    "    If simplify == True, we only print one entry and append a string to indicate there are more\n",
    "    \"\"\"\n",
    "    m_sorted = sorted(matches, key=lambda x: x.Pk_index)\n",
    "    m_grps = groupby(m_sorted, lambda x: x.Pk_index)     # group by peak index...groups with more than one entry have redundancy\n",
    "        \n",
    "    for k, grp in m_grps:\n",
    "        \n",
    "        if sort_order == 'label_len':\n",
    "            grp_as_list = sorted(list(grp), key=lambda x: len(x.TargetIon.Label))\n",
    "        elif sort_order == 'error':\n",
    "            grp_as_list = sorted(list(grp), key=lambda x: abs(x.Error))\n",
    "    \n",
    "        simplifying = simplify and (len(grp_as_list) > 1)   # do we need to simplify the output?\n",
    "\n",
    "        for g in grp_as_list:\n",
    "   \n",
    "            desc = print_fn(g, peaks)   \n",
    "                \n",
    "            if simplifying:\n",
    "                desc += f' [1/{len(grp_as_list)}]'\n",
    "            \n",
    "            print(desc)\n",
    "            \n",
    "            if simplifying: break  #only print one line\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a utility function to help sort peak lists\n",
    "def get_peak_mass_from_match(m, peaks):    \n",
    "    return peaks[m.Pk_index].Mass\n",
    "\n",
    "def get_count_and_tic(grp, peaks):\n",
    "    \"\"\"\n",
    "    Given a group of matches determine the number of unique peaks and the sum of the intensity they explain\n",
    "    \"\"\"\n",
    "    \n",
    "    last_index = 0\n",
    "    count = 0\n",
    "    tic = 0\n",
    "    \n",
    "    for m in grp:\n",
    "        \n",
    "        if m.Pk_index == last_index: continue\n",
    "        \n",
    "        last_index = m.Pk_index\n",
    "        \n",
    "        count += 1\n",
    "        tic += peaks[last_index].Inten\n",
    "        \n",
    "    return count, tic\n",
    "    \n",
    "def print_root_groups(matches, peaks, print_fn, suppress_isotopes=False, suppress_print=False):    \n",
    "    \"\"\"\n",
    "    Use the provided print function (e.g. match_as_str) to print the matches provided\n",
    "    We group the matches by the root first and sort by mass; if suppress_isotopes is True we skip\n",
    "    isotope matches (i.e. those where the Pk_index and MonoPeak are different)\n",
    "    Also returns a dictionary of group:(count, tic) that summarizes each group\n",
    "    \"\"\"\n",
    "    \n",
    "    r_sorted = sorted(matches, key=lambda x: x.TargetIon.Root)\n",
    "    r_grps = groupby(r_sorted, lambda x: x.TargetIon.Root)     # group by target root\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for k, grp in r_grps:\n",
    "        \n",
    "        # get the group as a list sorted by length of mass\n",
    "        grp_as_list = sorted(list(grp), key= lambda x: get_peak_mass_from_match(x, peaks))\n",
    "    \n",
    "        count, tic = get_count_and_tic(grp_as_list, peaks)\n",
    "        \n",
    "        if not suppress_print:\n",
    "            \n",
    "            # we can suppress isotopes by only selecting matches where the peak index and mono peak index are the same\n",
    "            if suppress_isotopes:  \n",
    "                grp_as_list = [m for m in grp_as_list if m.Pk_index == m.MonoPeak]\n",
    "            \n",
    "            for g in grp_as_list:          \n",
    "                print(print_fn(g, peaks))\n",
    "         \n",
    "            print()    # blank line after each group       \n",
    "        \n",
    "        result[k] = (count, tic)\n",
    "      \n",
    "    return result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a list of limits, i.e. (comp, max count) tuples, to a string\n",
    "# skip any with max_count = 0 and join the rest with commas\n",
    "def limits_as_string(limits):\n",
    "    non_zero_limits = [l for l in limits if l[1] > 0]\n",
    "    if len(non_zero_limits) == 0:\n",
    "        return \"\"\n",
    "    else:\n",
    "        desc = \",\".join([f'{l}' for l in non_zero_limits])\n",
    "        return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the conditions line and print each part on a separate line..\n",
    "def print_conditions(ion_file, conds_line):\n",
    "    \n",
    "    print(ion_file)\n",
    "    \n",
    "    parts = conds_line.split(';')\n",
    "    \n",
    "    for p in parts:\n",
    "        print(p.strip())\n",
    "        \n",
    "def write_conditions(file_path, ion_file, desc, conds_line=None, match_conds=None, root_res=None, tic=0):\n",
    "    \n",
    "    with open(file_path, 'w') as f:\n",
    "        \n",
    "        print(desc, file=f)\n",
    "        print(ion_file, file=f)\n",
    "    \n",
    "        if conds_line:\n",
    "            parts = conds_line.split(';')\n",
    "    \n",
    "            for p in parts:\n",
    "                print(p.strip(), file=f)\n",
    "        \n",
    "        if match_conds:\n",
    "            for mc in match_conds:\n",
    "                print(mc, file=f)\n",
    "                \n",
    "        if root_res:\n",
    "            print (file=f)\n",
    "\n",
    "            for g in grp_stats:\n",
    "                count, int_sum = grp_stats[g]\n",
    "                if tic:\n",
    "                    percent_tic = int_sum * 100 / tic\n",
    "                    print(f'{g:20}\\tcount:{count:4}\\tinten sum {int_sum:12.1f}\\t% tic {percent_tic:5.1f}', file=f)\n",
    "                else:\n",
    "                    print(f'{g:20}\\tcount:{count:4}\\tinten sum {int_sum:12.1f}', file=f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Setup\n",
    "\n",
    "Define paths to the peak list and target ion list. Here we use a directory that is shared with the calculator to facilitate interactive use (we can run the calculator notebook, switch to one this and re-run it to see the changes). \n",
    "\n",
    "The lines marked 'UPDATE!' must be changed to relect the local environment. Windows users need to specify the disk, i.e.\n",
    "\n",
    "       data_path = 'C:' + os.sep + os.path.join('Users','ronbonner','Data', 'SharedData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ronbonner/Data/SharedData/Test\n"
     ]
    }
   ],
   "source": [
    "data_path = os.sep + os.path.join('Users','ronbonner','Data', 'SharedData', 'Test')      # UPDATE!\n",
    "\n",
    "print(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_matches = True                # do we want to save the matched peaks (as mass, inten, match name)?\n",
    "local_files = False\n",
    "include_large_unmatched = False      # do we want to include the larger unmatched peaks (by default > 1% base peak inten)\n",
    "include_date_in_file_name = False\n",
    "\n",
    "# the match window can be in amu or ppm (relative to mass); if both are speciefied the larger (at any mass) is used\n",
    "amu_window = 0.005     # amu half window for peak matching\n",
    "ppm_window = 10        # ppm half window for peak matching\n",
    "\n",
    "# We only look for the 13C isotopes of matched peaks\n",
    "c13_half_window = 0.003     # for matching 13C isotopes\n",
    "max_C13_count = 4           # maximum number of 13C's to look for\n",
    "c13_rt_window = 0.2         # main matched peaks and isotopes must have RTs that differ by less than this\n",
    "require_lower_c13_inten = True  # if True, potential isotope peaks must have a lower intensity than the matched peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 0 Int: 2 RT: -1\n",
      "/Users/ronbonner/Data/SharedData/Test/S_4 MeOH FA pks 0.2 percent.txt\n",
      "2932, peaks read. TIC 397185.9, base peak inten 107995.2764 \n"
     ]
    }
   ],
   "source": [
    "# Read the peak file\n",
    "\n",
    "peak_file = 'S_4 MeOH FA pks 0.2 percent.txt'\n",
    "peak_file_path = os.path.join(data_path, peak_file)\n",
    "\n",
    "peaks, tic, base_peak_mass, base_peak_inten, has_RT = read_peak_list(peak_file_path)\n",
    "\n",
    "rt_str = \"has rt\" if has_RT else \"\"\n",
    "\n",
    "print(peak_file_path)\n",
    "print(f'{len(peaks)}, peaks read. TIC {tic:.1f}, base peak inten {base_peak_inten} {rt_str}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ronbonner/Data/SharedData/Test/DiMeSA ions pos.txt\n",
      "108 target ions read\n",
      "DiMeSA ions pos.txt\n",
      "Time:210622_070753\n",
      "Compounds:DiMeSA\n",
      "Multimer_limit:3\n",
      "Heterodimers:True\n",
      "Polarity:positive\n",
      "Adducts:('Na-H', 2),('K-H', 2),('Ca-2H', 1)\n",
      "Max adduct count:5\n",
      "Losses:('H2O', 1)\n"
     ]
    }
   ],
   "source": [
    "# Read the target ion file\n",
    "\n",
    "ion_file =  'DiMeSA ions pos.txt'   #\n",
    "compounds_as_string = 'DiMeSA'\n",
    "\n",
    "ion_path = os.path.join(data_path, ion_file)\n",
    "\n",
    "ions, conditions = read_ion_list(ion_path)\n",
    "\n",
    "print(ion_path)\n",
    "\n",
    "print(f'{len(ions)} target ions read')\n",
    "\n",
    "if conditions:\n",
    "    print_conditions(ion_file, conditions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Match ions\n",
    "\n",
    "We first match the ions generated by the calculator. In a subsequent step we look specifically for the 13C forms of matched peaks.\n",
    "\n",
    "The code allows for the possibility that any peak may match multiple targets, and any target may be matched by multple peaks. This is can occur if retention times are present (e.g. if there are isomers at different RT), if there are very close masses (e.g. from very high resolution data) or if there are many close target ions generated from complex sets of adducts, losses, heterodimers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 peaks matched (44.4% tic), 26 total matches from 2932 peaks\n"
     ]
    }
   ],
   "source": [
    "# Get the current time for use in the peak name and conditions\n",
    "current_time = datetime.datetime.now().replace(microsecond=0)\n",
    "curr_time_str = current_time.strftime('%y%m%d_%H%M%S')\n",
    "\n",
    "peak_index, ion_index, peaks_matched = 0, 0, 0\n",
    "\n",
    "matches = []   # this is going to end up as a list of Match tuples : (peak index, matched target)\n",
    "\n",
    "# Loop all the values and peaks looking for matches within the specified window\n",
    "while (ion_index < len(ions)) and (peak_index < len(peaks)):\n",
    "\n",
    "    this_peak, this_ion = peaks[peak_index], ions[ion_index]\n",
    "    low_peak, high_peak = get_mass_limits(this_peak.Mass, amu_window, ppm_window)\n",
    "    \n",
    "    # Increment the ion index if its Mass is too low and the peak if it's too high\n",
    "    if this_ion.Mass < low_peak:\n",
    "        ion_index += 1\n",
    "        continue\n",
    "\n",
    "    if this_ion.Mass > high_peak:\n",
    "        peak_index += 1\n",
    "        continue\n",
    "\n",
    "    # save peak index and ion composition\n",
    "    # since there may be more than one peak that matches this ion value, we look ahead at the peaks\n",
    "    # using a separate index so the current peak can be used with the next ion value\n",
    "    # we also track the ions matched since some ions may have more than one matching peak\n",
    "    \n",
    "    matches.append(Match(peak_index, this_ion, peak_index, this_peak.Mass - this_ion.Mass))    # reference to peak, this composition and the monopeak (this one)\n",
    "    peaks_matched += 1   \n",
    "    \n",
    "    look_ahead = peak_index + 1\n",
    " \n",
    "    # look ahead at the peaks while they're still within the search window and add any matches to the list\n",
    "    while (look_ahead < len(peaks)):\n",
    "                \n",
    "        look_ahead_peak = peaks[look_ahead]\n",
    "        \n",
    "        if(look_ahead_peak.Mass - this_ion.Mass) > get_mz_window(this_peak.Mass, amu_window, ppm_window):\n",
    "            break\n",
    "            \n",
    "        matches.append(Match(look_ahead, this_ion, look_ahead, look_ahead_peak.Mass - this_ion.Mass))\n",
    "        look_ahead +=1\n",
    "        peaks_matched += 1 \n",
    "\n",
    "\n",
    "    ion_index += 1 # increment ion index but not peak_index - there may be more than one ion within the window..\n",
    "\n",
    "matched_indices, percent_tic_matched = get_match_stats(matches, peaks, tic)\n",
    "\n",
    "matched_indices = sorted(matched_indices)\n",
    "initial_matches = f'{len(matched_indices)} peaks matched ({percent_tic_matched:.1f}% tic), {len(matches)} total matches from {len(peaks)} peaks'\n",
    "print(initial_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 peaks matched (47.4% tic), 59 total matches from 2932 peaks\n"
     ]
    }
   ],
   "source": [
    "# Look for C13 isotopes of matched peaks\n",
    "# In addition to looking for mass deltas of 1.003, we test that the retention time differences are within a specified tolerance\n",
    "# we can always apply this test since missing RTs are stored as zero so the delta is guaranteed to be less than any positive, non-zero tolerance\n",
    "# We can optionally require that the intensity of isotope peaks be less than the initial matched peak\n",
    "# We look at the peak indices since we only need to test a peak once, even if it has multiple matches\n",
    "\n",
    "c13_matches = []\n",
    "\n",
    "last_matched_mass = 0\n",
    "last_peak_index = -1\n",
    "\n",
    "# make sure the peaks are in peak (= mass) order\n",
    "matches = sorted(matches, key=lambda x: x.Pk_index)\n",
    "\n",
    "for m in matches:    \n",
    "        \n",
    "    if m.Pk_index == last_peak_index:    #only need to look at each peak once\n",
    "        continue\n",
    "\n",
    "    peak_index = m.Pk_index    \n",
    "    last_peak_index = peak_index\n",
    "        \n",
    "    m_mass, m_inten, m_rt = peaks[peak_index]     # get the matched peak...\n",
    "    \n",
    "    tracking = False #345 < m_mass < 350\n",
    "    \n",
    "    if tracking: print('m_mass', m_mass, m_rt)\n",
    "    \n",
    "    next_peak_index = peak_index      #...and start looking for isotopes at the next higher peak\n",
    "        \n",
    "    keep_going = True\n",
    "    \n",
    "    for c13_count in range(1, max_C13_count+1):  #look for 1,2,3... C13\n",
    "    \n",
    "        c13_mass = m_mass + (c13_count * 1.003)   # expected c13 mass\n",
    "        c13_name = f'{m_mass:.4f}(+{c13_count})'  # name is based on mono mass with (+1) etc apended\n",
    "        \n",
    "        low_peak, high_peak = get_mass_limits(c13_mass, c13_half_window, 10)\n",
    "        \n",
    "        if tracking: print('13c target', c13_mass, low_peak, high_peak)\n",
    "        \n",
    "        while next_peak_index < len(peaks) - 1:   # -1 since we're going to increment it\n",
    "            \n",
    "            next_peak_index += 1  # point at next value in peak list\n",
    "                \n",
    "            next_peak_mass, next_peak_inten, next_peak_rt = peaks[next_peak_index]\n",
    "            \n",
    "            if tracking: print('    ', next_peak_mass, next_peak_rt, next_peak_mass-m_mass)\n",
    "            \n",
    "            # mass is out of range  \n",
    "            if next_peak_mass > high_peak:\n",
    "                keep_going = False       # when one isotope is not matched we abort and stop looking for more\n",
    "                if tracking: print('out of range:', next_peak_mass, next_peak_rt, next_peak_mass-m_mass)\n",
    "                break\n",
    "            \n",
    "            # if the mass is in range we also check that the RT is within a window...\n",
    "            # Note: it's OK to always apply this test since if there is no RT the values will be zero\n",
    "            # and therefore the delta will be less than the threshold\n",
    "            rt_ok = abs(m_rt-next_peak_rt)< c13_rt_window\n",
    "            \n",
    "            if not require_lower_c13_inten:\n",
    "                inten_ok = True\n",
    "            else:\n",
    "                inten_ok = next_peak_inten < m_inten\n",
    "            \n",
    "            if tracking: print(rt_ok, inten_ok)\n",
    "\n",
    "            if next_peak_mass > low_peak and rt_ok and inten_ok:\n",
    "                c13 = Target(c13_mass, m.TargetIon.Root, c13_name)\n",
    "                c13_matches.append(Match(next_peak_index, c13, peak_index, next_peak_mass - c13_mass))\n",
    "                if tracking: print('13c match', c13_count, next_peak_mass, next_peak_rt, next_peak_mass-m_mass, inten_ok)\n",
    "                m_inten = next_peak_inten   #update target inten\n",
    "                break     # and look for the next higher isotope\n",
    "        \n",
    "        if not keep_going:\n",
    "            break     # leave 13c for loop   \n",
    "\n",
    "matches += c13_matches\n",
    "\n",
    "matches = sorted(matches, key = lambda x: x.Pk_index)  # sort by peak index...\n",
    "\n",
    "matched_indices, percent_tic_matched = get_match_stats(matches, peaks, tic)\n",
    "\n",
    "after_13c_match = f'{len(matched_indices)} peaks matched ({percent_tic_matched:.1f}% tic), {len(matches)} total matches from {len(peaks)} peaks'\n",
    "print(after_13c_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Print, review, save\n",
    "\n",
    "Cells illustrate various ways to report the matches:\n",
    "\n",
    "- print all or some of them inside the notebook; there is an option to show all matches, including redundant ones, or to simplify the output to only show the shortest\n",
    "- count the number of peaks that have redundant matches and optionally print them\n",
    "- print the unmatched peaks above a thershold (as percentage of the base peak intensity)\n",
    "\n",
    "Reviewing redundant peaks is useful as it can indicate that parameters need changing (if there are too many), for example: reduce the matching tolerance, reduce the number of target ions, etc.\n",
    "\n",
    "The unmatched peak list is a good way to find peaks that still need to be explained and is the first step in further interpretation.\n",
    "\n",
    "The detailed list os matched can be written to a file for use with the Interpret module or elsewhere and a final cell summarizes the parameters and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 peaks matched (47.4% tic), 59 total matches from 2932 peaks\n",
      "   63:  129.0524 ( -2.2)   0.00       3856.4   129.0546     63  DiMeSA        DiMeSA-H2O.H+\n",
      "   65:  130.0551 ( -0.3)   0.00        184.0   130.0554     63  DiMeSA        129.0524(+1)\n",
      "   68:  131.0564 ( -1.9)   0.00         37.2   131.0584     63  DiMeSA        129.0524(+2)\n",
      "  111:  147.0622 ( -3.0)   0.00       1505.1   147.0652    111  DiMeSA        DiMeSA.H+\n",
      "  114:  148.0657 (  0.5)   0.00         94.3   148.0652    111  DiMeSA        147.0622(+1)\n",
      "  119:  149.0676 ( -0.6)   0.00         18.4   149.0682    111  DiMeSA        147.0622(+2)\n",
      "  125:  151.0337 ( -2.9)   0.00         44.9   151.0366    125  DiMeSA        DiMeSA-H2O.Na-H.H+\n",
      "  130:  152.0372 (  0.5)   0.00         16.5   152.0367    125  DiMeSA        151.0337(+1)\n",
      "  169:  166.9990 ( -2.6)   0.00        121.8   167.0016    169  DiMeSA        DiMeSA-H2O.Ca-2H.H+\n",
      "  174:  168.0035 (  1.4)   0.00         12.0   168.0020    169  DiMeSA        166.9990(+1)\n",
      "  179:  169.0455 ( -1.6)   0.00     107995.3   169.0471    179  DiMeSA        DiMeSA.Na-H.H+\n",
      "  227:  170.0473 ( -1.2)   0.00       4139.0   170.0485    179  DiMeSA        169.0455(+1)\n",
      "  307:  171.0490 ( -2.6)   0.00        466.6   171.0515    179  DiMeSA        169.0455(+2)\n",
      "  398:  172.0518 ( -2.7)   0.00         70.3   172.0545    179  DiMeSA        169.0455(+3)\n",
      "  488:  173.0135 ( -5.0)   0.00         27.4   173.0185    488  DiMeSA        DiMeSA-H2O.(Na-H)2.H+\n",
      "  493:  173.0589 (  1.3)   0.00         19.3   173.0575    179  DiMeSA        169.0455(+4)\n",
      "  588:  185.0100 ( -2.1)   0.00       2279.0   185.0121    588  DiMeSA        DiMeSA.Ca-2H.H+\n",
      "  597:  186.0122 ( -0.7)   0.00        129.2   186.0130    588  DiMeSA        185.0100(+1)\n",
      "  600:  187.0149 ( -1.1)   0.00         53.6   187.0160    588  DiMeSA        185.0100(+2)\n",
      "  621:  191.0265 ( -2.6)   0.00      10888.2   191.0291    621  DiMeSA        DiMeSA.(Na-H)2.H+\n",
      "  626:  192.0300 (  0.5)   0.00        442.4   192.0295    621  DiMeSA        191.0265(+1)\n",
      "  630:  193.0310 ( -1.5)   0.00         80.0   193.0325    621  DiMeSA        191.0265(+2)\n",
      "  701:  206.9997 ( -3.3)   0.00        448.0   207.0030    701  DiMeSA        DiMeSA.Na-H.K-H.H+\n",
      "  706:  208.0013 ( -1.4)   0.00         43.4   208.0027    701  DiMeSA        206.9997(+1)\n",
      "  823:  228.9807 ( -4.2)   0.00         25.2   228.9849    823  DiMeSA        DiMeSA.(Na-H)2.K-H.H+ [1/2]\n",
      " 1207:  293.1200 ( -3.1)   0.00        100.2   293.1231   1207  DiMeSA        (DiMeSA)2.H+\n",
      " 1213:  294.1240 (  1.0)   0.00         18.0   294.1230   1207  DiMeSA        293.1200(+1)\n",
      " 1221:  295.1276 (  1.6)   0.00         12.8   295.1260   1207  DiMeSA        293.1200(+2)\n",
      " 1318:  313.0550 ( -4.5)   0.00        103.7   313.0595   1318  DiMeSA        (DiMeSA)2-H2O.Ca-2H.H+\n",
      " 1326:  314.0588 (  0.8)   0.00         19.5   314.0580   1318  DiMeSA        313.0550(+1)\n",
      " 1329:  315.1017 ( -3.3)   0.00      12866.1   315.1050   1329  DiMeSA        (DiMeSA)2.Na-H.H+\n",
      " 1331:  316.1040 ( -0.7)   0.00       1152.6   316.1047   1329  DiMeSA        315.1017(+1)\n",
      " 1343:  319.0768 (  0.4)   0.00        130.9   319.0764   1343  DiMeSA        (DiMeSA)2-H2O.(Na-H)2.H+\n",
      " 1354:  320.0813 (  1.5)   0.00         24.5   320.0798   1343  DiMeSA        319.0768(+1)\n",
      " 1425:  331.0658 ( -4.2)   0.00       7150.0   331.0700   1425  DiMeSA        (DiMeSA)2.Ca-2H.H+\n",
      " 1433:  332.0693 (  0.5)   0.00        691.7   332.0688   1425  DiMeSA        331.0658(+1)\n",
      " 1439:  333.0693 ( -2.6)   0.00        140.7   333.0718   1425  DiMeSA        331.0658(+2)\n",
      " 1467:  337.0834 ( -3.6)   0.00       9359.8   337.0870   1467  DiMeSA        (DiMeSA)2.(Na-H)2.H+\n",
      " 1475:  338.0860 ( -0.4)   0.00        870.2   338.0864   1467  DiMeSA        337.0834(+1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the matches for review. To print a few matches use, for example, matches[:40]\n",
    "# If there are redundant matches (i.e. more than one match for a peak) they are sorted by length, the idea being that that the simplest is more likely.\n",
    "# If 'simplify' is True, only the first label (shortest) is printed with a notation indicating that there are others\n",
    "\n",
    "print(after_13c_match)\n",
    "print_match_list(matches[:40], peaks, match_as_str, simplify=True)  # remove '40' to see all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiMeSA      \tcount:  58\tinten sum     188227.2,  47.4% tic\n"
     ]
    }
   ],
   "source": [
    "# We can also organize the matches by root before printing..\n",
    "# The matches are sorted in peak (mass) order and isotopes can be skipped by seeting suppres_isotopes = True\n",
    "# print_root_groups returns a dictionary which summarizes the results for each root group\n",
    "#\n",
    "# i.e. number of members, intensity and percent tic...if suppress_print is true we just get the diictionary\n",
    "# if suppress_print is true the peaks are not printed and only the summary dictinary is reurned\n",
    "\n",
    "grp_stats = print_root_groups(matches, peaks, match_as_str, suppress_isotopes = False, suppress_print=True)\n",
    "\n",
    "for g in grp_stats:\n",
    "    count, int_sum = grp_stats[g]\n",
    "    percent_tic = int_sum * 100 / tic\n",
    "    print(f'{g:12}\\tcount:{count:4}\\tinten sum {int_sum:12.1f}, {percent_tic:5.1f}% tic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  redundant peaks have 2 matches\n",
      "\n",
      "  823:  228.9807 ( -4.2)   0.00         25.2   228.9849    823  DiMeSA        DiMeSA.(Na-H)2.K-H.H+\n",
      "  823:  228.9807 (  4.7)   0.00         25.2   228.9760    823  DiMeSA        DiMeSA.(Na-H)2.Ca-2H.H+\n"
     ]
    }
   ],
   "source": [
    "# It can be useful to review the redundant matches, i.e. peaks that have multiple matches, since these can indicate adduct/loss/modifcation combinations\n",
    "# that result in the same mass suggesting opprotunities to simplify the lists\n",
    "\n",
    "redundant_peak_count, redundant_matches = get_redundant_matches(matches)\n",
    "\n",
    "print(redundant_peak_count,' redundant peaks have', len(redundant_matches), 'matches')\n",
    "\n",
    "print_redundant_matches = True\n",
    "\n",
    "# To make the list easier to read, we add a blank line between the redundant groups\n",
    "if print_redundant_matches:\n",
    "    \n",
    "    last_index = -1\n",
    "    for m in redundant_matches:\n",
    "        if m.Pk_index != last_index:   # when the Pk_index changes...\n",
    "            print()\n",
    "            last_index = m.Pk_index\n",
    "            \n",
    "        print(match_as_str(m, peaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is useful to print the largest unmatched peaks since these suggest opportunities to modify the Calculator parameters\n",
    "# to get greater coverage. Some peaks may be easy to explain (unusual isotopes, obvious losses, etc.)\n",
    "# Unexplained, large peaks can be included in the Calculator, for example,  ('x544', 544.2148) was included in the Ibuprofen compound\n",
    "# list to explain ions at 562 and 567 corresponding to X+NH4+ and X+Na+\n",
    "\n",
    "# get the indices and peaks from \n",
    "threshold_percent = 0.0   #default threshold\n",
    "bpi_percent_thresh = threshold_percent * base_peak_inten / 100   # convert to counts\n",
    "\n",
    "unmatched_indices = get_unmatched_indices(matched_indices, peaks, bpi_percent_thresh)  # get the unmatched peask > 1% base peak\n",
    "\n",
    "unmatched_peaks = [peaks[pi] for pi in unmatched_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def rt_grouper(peaks, max_rt_gap):\n",
    "\n",
    "    rt_grps = defaultdict(list)\n",
    "    rt_grp_index = 0\n",
    "    rt_last = 0\n",
    "\n",
    "    # simple group by rt routine\n",
    "    for p in sorted(peaks, key=lambda x: x.RT):\n",
    "        rt = p.RT\n",
    "        if (rt - rt_last) > max_rt_gap:\n",
    "            rt_grp_index += 1\n",
    "            \n",
    "        rt_grps[rt_grp_index] += [p]\n",
    "        \n",
    "        rt_last = rt\n",
    "    \n",
    "    return rt_grps\n",
    "\n",
    "def write_mgf(mgf_path,rt_grps, min_inten=5):\n",
    "    \n",
    "    with open(mgf_path,'w') as out_f:\n",
    "\n",
    "        for g in rt_grps:\n",
    "\n",
    "            int_sum = sum(p.Inten for p in rt_grps[g])\n",
    "\n",
    "            rt_min, rt_max = rt_grps[g][0].RT, rt_grps[g][0].RT\n",
    "\n",
    "            rt_str = \"RTINSECONDS={:.2f}\\n\".format(rt_min * 60.0)\n",
    "\n",
    "            title_str = f\"TITLE=RT grp {g}, rt {rt_min:.2f}-{rt_max:.2f} min., {len(rt_grps[g])} members\\n\"\n",
    "\n",
    "    #         print (title_str)\n",
    "\n",
    "            out_f.write(\"BEGIN IONS\\n\")\n",
    "            out_f.write(title_str)\n",
    "            out_f.write(rt_str) \n",
    "\n",
    "            for p in sorted(rt_grps[g], key=lambda x:x.Mass):\n",
    "                m_str = f'{p.Mass:.4f}\\t{p.Inten if p.Inten > 0 else min_inten}\\n'\n",
    "                out_f.write(m_str)\n",
    "\n",
    "            out_f.write(\"END IONS\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 matched groups\n",
      "1 unmatched groups\n"
     ]
    }
   ],
   "source": [
    "MatchedPeak = namedtuple('MatchedPeak', 'Mass RT Inten TargetMass TargetLabel MonoPeak Error')   \n",
    "\n",
    "matched_peaks = []\n",
    "\n",
    "for m in matches:\n",
    "    p = peaks[m.Pk_index]\n",
    "    t = m.TargetIon\n",
    "    mp = MatchedPeak(p.Mass, p.RT, p.Inten, t.Mass, t.Label,m.MonoPeak, Error=m.Error)\n",
    "    matched_peaks.append(mp)\n",
    "    \n",
    "matched_grps = rt_grouper(matched_peaks, 0.1)\n",
    "\n",
    "unmatched_grps = rt_grouper(unmatched_peaks, 0.0)\n",
    "\n",
    "print(len(matched_grps), 'matched groups')\n",
    "print(len(unmatched_grps), 'unmatched groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_mgfs = False\n",
    "\n",
    "if write_mgfs:\n",
    "    mgf_dir, _ = os.path.splitext(peak_file_path)    # path without extension\n",
    "\n",
    "    mgf_path = f'{mgf_dir} {compounds_as_string} matched.mgf'       \n",
    "\n",
    "    write_mgf(mgf_path, matched_grps)\n",
    "\n",
    "    print (\"Finished matched\", mgf_path)\n",
    "\n",
    "    mgf_path = f'{mgf_dir} {compounds_as_string} residual.mgf'       \n",
    "\n",
    "    write_mgf(mgf_path, unmatched_grps)\n",
    "\n",
    "    print (\"Finished unmatched\", mgf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2874 unmatched Largest unmatched 463.134308, 42577.39799 39.4% base\n"
     ]
    }
   ],
   "source": [
    "# print the unmatched peaks above threshold and find the largest\n",
    "\n",
    "print_unmatched = False\n",
    "\n",
    "unmatched_mass, largest_unmatched_inten = 0,0\n",
    "\n",
    "for pi in unmatched_peaks:\n",
    "    percent_base_peak = pi.Inten * 100/ base_peak_inten\n",
    "    if print_unmatched:\n",
    "        print(f'{pi.Mass:10.4f} {pi.RT:8.2f} {pi.Inten:10.0f} {percent_base_peak:8.2f}% base peak')\n",
    "    \n",
    "    if pi.Inten > largest_unmatched_inten:\n",
    "        unmatched_mass, largest_unmatched_inten = pi.Mass,pi.Inten\n",
    "\n",
    "large_inten_rel = largest_unmatched_inten * 100/ base_peak_inten\n",
    "\n",
    "largest_unmatched_string = f'Largest unmatched {unmatched_mass}, {largest_unmatched_inten} {large_inten_rel:.1f}% base'\n",
    "\n",
    "print(len(unmatched_indices), 'unmatched', largest_unmatched_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Match time: 210622_103236', 'Peaks file: /Users/ronbonner/Data/SharedData/Test/S_4 MeOH FA pks 0.2 percent.txt', '2932 peaks, tic 397185.9, base peak 169.04554, inten 107995.3', 'Matching amu half window: 0.005', 'Matching ppm half window: 10 ppm', 'Looking for <= 4 13C isotopes with half window 0.003', '25 peaks matched (44.4% tic), 26 total matches from 2932 peaks', 'After 13C match 58 peaks matched (47.4% tic), 59 total matches from 2932 peaks', '2874 unmatched peaks gt 0.0%, Largest unmatched 463.134308, 42577.39799 39.4% base']\n"
     ]
    }
   ],
   "source": [
    "# We make a list of strings containing the match conditions so they can be saved to the ouput files\n",
    "# and printed (below)\n",
    "match_conditions = [f'Match time: {curr_time_str}']\n",
    "match_conditions.append(f'Peaks file: {peak_file_path}')\n",
    "match_conditions.append(f'{len(peaks)} peaks, tic {tic:.1f}, base peak {base_peak_mass:.5f}, inten {base_peak_inten:.1f}')\n",
    "match_conditions.append(f'Matching amu half window: {amu_window}')\n",
    "match_conditions.append(f'Matching ppm half window: {ppm_window} ppm')\n",
    "\n",
    "match_conditions.append(f'Looking for <= {max_C13_count} 13C isotopes with half window {c13_half_window}')\n",
    "\n",
    "match_conditions.append(initial_matches)\n",
    "match_conditions.append(f'After 13C match {after_13c_match}')\n",
    "\n",
    "match_conditions.append(f'{len(unmatched_indices)} unmatched peaks gt {threshold_percent}%, {largest_unmatched_string}')\n",
    "\n",
    "print(match_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ronbonner/Data/SharedData/Test/S_4 MeOH FA pks 0.2 percent_DiMeSA\n"
     ]
    }
   ],
   "source": [
    "# make one output path for all save operations\n",
    "out_path, _ = os.path.splitext(peak_file_path)    # path without extension\n",
    "\n",
    "out_path = re.sub(' residual$', '', out_path)   # remove ' residual' if it's at the end of the file path\n",
    "\n",
    "out_path += f'_{compounds_as_string}'\n",
    "\n",
    "print (out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ronbonner/Data/SharedData/Test/S_4 MeOH FA pks 0.2 percent_DiMeSA matches.txt\n",
      "59  lines written\n"
     ]
    }
   ],
   "source": [
    "include_large_unmatched = False\n",
    "\n",
    "# Save the match list if needed\n",
    "# Note: The peak_file_path will already reflect the setting of 'local_files' so we don't need to test it again\n",
    "# The code allows the largest unmatched peaks to be included if desired by creating empty matches for them\n",
    "if save_matches:\n",
    "    \n",
    "    if include_date_in_file_name:\n",
    "        f_path = f'{out_path} matches {curr_time_str}.txt'\n",
    "    else:\n",
    "        f_path = f'{out_path} matches.txt'       \n",
    "    \n",
    "    to_save = matches\n",
    "    \n",
    "    # If we want the unmatched ions, we generate an empty Match tuple for each and append them to the actual matches\n",
    "    # Empty tuple has Pk_index, an empty target ion, the peak index is the mono peak, and an error of 0\n",
    "    if include_large_unmatched:\n",
    "        to_save = matches + [(i, Target(0,'', 'None'), i, 0) for i in unmatched_indices]\n",
    "    \n",
    "    to_save = sorted(to_save, key = lambda x: x[0])\n",
    "\n",
    "    lines_written_count = save_matches_to_file(f_path, to_save, peaks, conditions, match_conditions, with_details=True)\n",
    "    \n",
    "    print(f_path)\n",
    "    print(lines_written_count, ' lines written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ronbonner/Data/SharedData/Test/S_4 MeOH FA pks 0.2 percent_DiMeSA residual.txt\n",
      "2874  lines written\n"
     ]
    }
   ],
   "source": [
    "save_unmatched = True\n",
    "\n",
    "# Save the match list if needed\n",
    "# Note: The peak_file_path will already reflect the setting of 'local_files' so we don't need to test it again\n",
    "# The code allows the largest unmatched peaks to be included if desired by creating empty matches for them\n",
    "if save_unmatched:\n",
    "\n",
    "    if include_date_in_file_name:\n",
    "        save_path = f'{out_path} residual {curr_time_str}.txt'\n",
    "    else:\n",
    "        save_path = f'{out_path} residual.txt'       \n",
    "  \n",
    "    to_save = matches\n",
    "    \n",
    "    with open(save_path,'w') as f:\n",
    "        for pi in unmatched_peaks:\n",
    "            print(f'{pi.Mass:.4f}\\t{pi.Inten:.0f}', file=f)\n",
    "    \n",
    "    print(save_path)\n",
    "    print(len(unmatched_peaks), ' lines written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-22 10:32:36, 108 targets\n",
      "DiMeSA ions pos.txt\n",
      "DiMeSA ions pos.txt\n",
      "Time:210622_070753\n",
      "Compounds:DiMeSA\n",
      "Multimer_limit:3\n",
      "Heterodimers:True\n",
      "Polarity:positive\n",
      "Adducts:('Na-H', 2),('K-H', 2),('Ca-2H', 1)\n",
      "Max adduct count:5\n",
      "Losses:('H2O', 1)\n",
      "\n",
      "Match time: 210622_103236\n",
      "Peaks file: /Users/ronbonner/Data/SharedData/Test/S_4 MeOH FA pks 0.2 percent.txt\n",
      "2932 peaks, tic 397185.9, base peak 169.04554, inten 107995.3\n",
      "Matching amu half window: 0.005\n",
      "Matching ppm half window: 10 ppm\n",
      "Looking for <= 4 13C isotopes with half window 0.003\n",
      "25 peaks matched (44.4% tic), 26 total matches from 2932 peaks\n",
      "After 13C match 58 peaks matched (47.4% tic), 59 total matches from 2932 peaks\n",
      "2874 unmatched peaks gt 0.0%, Largest unmatched 463.134308, 42577.39799 39.4% base\n"
     ]
    }
   ],
   "source": [
    "# Finally we summarize the results\n",
    "\n",
    "desc = f'{current_time}, {len(ions)} targets'\n",
    "\n",
    "print (desc)\n",
    "print(ion_file)\n",
    "\n",
    "if conditions:\n",
    "    print_conditions(ion_file, conditions)\n",
    "\n",
    "print()\n",
    "for mc in match_conditions:\n",
    "    print (mc)\n",
    "\n",
    "if include_date_in_file_name:\n",
    "    res_path = f'{out_path} res {curr_time_str}.txt'\n",
    "else:\n",
    "    res_path = f'{out_path} res.txt'       \n",
    "\n",
    "write_conditions(res_path, ion_file, desc, conds_line=conditions, match_conds=match_conditions,\\\n",
    "                 root_res=grp_stats, tic=tic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
